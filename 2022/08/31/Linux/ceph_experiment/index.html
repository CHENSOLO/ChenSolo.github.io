

<!DOCTYPE html>
<html lang="zh-CN" >



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  
    <meta name="description" content="">
  
  <meta name="author" content="lemonchen">
  <meta name="keywords" content="">
  
  <title>Ceph部署实践 - lemonchen</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/googlecode.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"chensolo.github.io.git","root":"/","version":"1.8.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Never slack off</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Ceph部署实践">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-08-31 12:14" pubdate>
        2022年8月31日 中午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      10.8k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      183
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Ceph部署实践</h1>
            
            <div class="markdown-body">
              <h2 id="Ceph部署实践-虚拟环境下实现"><a href="#Ceph部署实践-虚拟环境下实现" class="headerlink" title="Ceph部署实践(虚拟环境下实现)"></a>Ceph部署实践(虚拟环境下实现)</h2><p><strong>osd</strong>：存储数据、复制数据、平衡数据、恢复数据等，与其它OSD间进行心跳检查等，并将一些变化情况上报给Ceph Monitor。</p>
<p><strong>mon</strong>：一个监视器，负责监视Ceph集群，维护Ceph集群的健康状态，同时维护着Ceph集群中的各种Map图。<br><strong>Mds</strong>: Ceph 元数据服务器（ MDS ）为 Ceph 文件系统存储元数据（也就是说，Ceph 块设备和 Ceph 对象存储不使用MDS ）。<br><strong>mgr</strong>：负责ceph集群管理，如pg map，对外提供集群性能指标（如cpeh -s 下IO信息），具有web界面的监控系统（dashboard）</p>
<h2 id="一、环境部署的准备"><a href="#一、环境部署的准备" class="headerlink" title="一、环境部署的准备"></a>一、环境部署的准备</h2><p><strong>使用Ceph版本</strong><br>Nautilus 14.2.9<br>Ceph-deploy：2.0.1</p>
<p><strong>节点信息</strong><br><img src="/img/Linux/ceph_info.png" srcset="/img/loading.gif"></p>
<p><strong>服务器系统版本：</strong></p>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs llvm">[root<span class="hljs-title">@localhost</span> ~]# cat /etc/centos-<span class="hljs-keyword">release</span><br>CentOS Linux <span class="hljs-keyword">release</span> <span class="hljs-number">7.6</span>.<span class="hljs-number">1810</span> (Core)<br><br></code></pre></td></tr></table></figure>
<p><strong>1、关闭防火墙以及SELinux</strong></p>
<figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs perl">[root@localhost ~]<span class="hljs-comment"># systemctl stop firewalld</span><br>[root@localhost ~]<span class="hljs-comment"># systemctl disable firewalld</span><br>Removed <span class="hljs-keyword">symlink</span> /etc/systemd/<span class="hljs-keyword">system</span>/multi-user.target.wants/firewalld.service.<br>Removed <span class="hljs-keyword">symlink</span> /etc/systemd/<span class="hljs-keyword">system</span>/dbus-org.fedoraproject.FirewallD1.service.<br>[root@localhost ~]<span class="hljs-comment"># sed -i  &quot;s/SELINUX=enforcing/SELINUX=permissive/g&quot; /etc/selinux/config</span><br>[root@localhost ~]<span class="hljs-comment">#</span><br>[root@localhost ~]<span class="hljs-comment"># setenforce 0</span><br>[root@localhost ~]<span class="hljs-comment"># getenforce</span><br>Permissive<br>[root@localhost ~]<span class="hljs-comment">#	nmcli conn mod ens33 ipv4.address 192.168.142.136/24 ipv4.gateway 192.168.142.2 ipv4.dns 192.168.142.2 ipv4.method manual </span><br></code></pre></td></tr></table></figure>

<p><strong>2、配置Hosts所有节点进行</strong></p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">保证集群内主机名称和ip解析正常(每个节点都需要配置)<br><span class="hljs-string">[root@localhost ~]</span># cat /etc/hosts<br><span class="hljs-number">127.0.0.1</span>   localhost localhost.localdomain localhost4 localhost4.localdomain4<br>::<span class="hljs-number">1</span>         localhost localhost.localdomain localhost6 localhost6.localdomain6<br><span class="hljs-number">192.168.142.134</span> ceph_node1<br><span class="hljs-number">192.168.142.135</span> ceph_node2<br><span class="hljs-number">192.168.142.136</span> ceph_node3<br><span class="hljs-string">[root@localhost ~]</span>#<br></code></pre></td></tr></table></figure>
<p><strong>3、创建部署用户及配置sudo权限(所有节点进行)</strong></p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs ruby">[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment"># useradd ceph-admin</span><br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment"># echo &quot;Lemon/123&quot; | passwd --stdin ceph-admin</span><br>Changing password <span class="hljs-keyword">for</span> user ceph-admin.<br><span class="hljs-symbol">passwd:</span> all authentication tokens updated successfully.<br><br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment"># echo &quot;ceph-admin ALL = NOPASSWD:ALL&quot; | tee /etc/sudoers.d/ceph-admin</span><br>ceph-admin <span class="hljs-variable constant_">ALL</span> = <span class="hljs-variable constant_">NOPASSWD</span><span class="hljs-symbol">:ALL</span><br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment"># chmod 0440 /etc/sudoers.d/ceph-admin      </span><br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment"># ll /etc/sudoers.d/ceph-admin</span><br>-r--r-----. <span class="hljs-number">1</span> root root <span class="hljs-number">30</span> Nov <span class="hljs-number">10</span> <span class="hljs-number">04</span><span class="hljs-symbol">:</span><span class="hljs-number">12</span> /etc/sudoers.d/ceph-admin<br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment">#</span><br><br><br>测试<br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment"># su - ceph-admin</span><br>[ceph-admin<span class="hljs-variable">@localhost</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@localhost</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@localhost</span> ~]<span class="hljs-variable">$ </span>ls<br>[ceph-admin<span class="hljs-variable">@localhost</span> ~]<span class="hljs-variable">$ </span>sudo su -<br>Last <span class="hljs-symbol">login:</span> Wed Nov <span class="hljs-number">10</span> <span class="hljs-number">01</span><span class="hljs-symbol">:</span><span class="hljs-number">54</span><span class="hljs-symbol">:</span><span class="hljs-number">32</span> <span class="hljs-variable constant_">EST</span> <span class="hljs-number">2021</span> from <span class="hljs-number">10.1</span>.<span class="hljs-number">130.7</span> on pts/<span class="hljs-number">1</span><br>[root<span class="hljs-variable">@localhost</span> ~]<span class="hljs-comment">#</span><br><br></code></pre></td></tr></table></figure>
<p><strong>4、配置ssh无密码访问（ceph_admin）上进行</strong><br>[ceph-admin@localhost ~]$ ssh-keygen<br>[ceph-admin@localhost ~]$ ssh-copy-id ceph-admin@ceph_node1<br>[ceph-admin@localhost ~]$ ssh-copy-id ceph-admin@ceph_node2<br>[ceph-admin@localhost ~]$ ssh-copy-id ceph-admin@ceph_node3</p>
<p><strong>5、配置ntp时间同步(所有节点进行)</strong></p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-id">#ceph_admin</span>节点安装<span class="hljs-selector-tag">ntp</span>，同步阿里云的时间，节点<span class="hljs-selector-tag">ceph_node1</span> <span class="hljs-selector-tag">ceph_node2</span> <span class="hljs-selector-tag">ceph_node3</span> 同步<span class="hljs-selector-tag">ceph_admin</span>节点的时间<br><span class="hljs-selector-attr">[root@admin ~]</span># <span class="hljs-selector-tag">sudo</span> <span class="hljs-selector-tag">yum</span> <span class="hljs-selector-tag">-y</span> <span class="hljs-selector-tag">install</span> <span class="hljs-selector-tag">ntp</span><br><span class="hljs-selector-attr">[root@admin ~]</span># <span class="hljs-selector-tag">sudo</span> <span class="hljs-selector-tag">vim</span> /<span class="hljs-selector-tag">etc</span>/<span class="hljs-selector-tag">ntp</span><span class="hljs-selector-class">.conf</span><br><span class="hljs-selector-attr">[root@admin ~]</span>#<br><span class="hljs-selector-attr">[root@admin ~]</span>#<br><span class="hljs-selector-attr">[root@admin ~]</span># <span class="hljs-selector-tag">grep</span> <span class="hljs-selector-tag">server</span> /<span class="hljs-selector-tag">etc</span>/<span class="hljs-selector-tag">ntp</span><span class="hljs-selector-class">.conf</span><br># <span class="hljs-selector-tag">Use</span> <span class="hljs-selector-tag">public</span> <span class="hljs-selector-tag">servers</span> <span class="hljs-selector-tag">from</span> <span class="hljs-selector-tag">the</span> <span class="hljs-selector-tag">pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> <span class="hljs-selector-tag">project</span>.<br><span class="hljs-selector-id">#server</span> <span class="hljs-number">0</span><span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> <span class="hljs-selector-tag">iburst</span><br><span class="hljs-selector-id">#server</span> <span class="hljs-number">1</span><span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> <span class="hljs-selector-tag">iburst</span><br><span class="hljs-selector-id">#server</span> <span class="hljs-number">2</span><span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> <span class="hljs-selector-tag">iburst</span><br><span class="hljs-selector-id">#server</span> <span class="hljs-number">3</span><span class="hljs-selector-class">.centos</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> <span class="hljs-selector-tag">iburst</span><br><span class="hljs-selector-tag">server</span> <span class="hljs-selector-tag">ntp1</span><span class="hljs-selector-class">.aliyun</span><span class="hljs-selector-class">.com</span>  #阿里云服务器<br><span class="hljs-selector-tag">server</span> <span class="hljs-number">127.127</span><span class="hljs-selector-class">.1</span><span class="hljs-selector-class">.0</span> <span class="hljs-selector-tag">iburst</span> #本地<span class="hljs-selector-tag">ntp</span>服务器，配置此项为了在外网<span class="hljs-selector-tag">ntp</span>连接异常的情况下还能保证<span class="hljs-selector-tag">ntp</span>的正常<br><span class="hljs-selector-id">#broadcast</span> <span class="hljs-number">192.168</span><span class="hljs-selector-class">.1</span><span class="hljs-selector-class">.255</span> <span class="hljs-selector-tag">autokey</span>        # <span class="hljs-selector-tag">broadcast</span> <span class="hljs-selector-tag">server</span><br><span class="hljs-selector-id">#broadcast</span> <span class="hljs-number">224.0</span><span class="hljs-selector-class">.1</span><span class="hljs-selector-class">.1</span> <span class="hljs-selector-tag">autokey</span>            # <span class="hljs-selector-tag">multicast</span> <span class="hljs-selector-tag">server</span><br><span class="hljs-selector-id">#manycastserver</span> <span class="hljs-number">239.255</span><span class="hljs-selector-class">.254</span><span class="hljs-selector-class">.254</span>         # <span class="hljs-selector-tag">manycast</span> <span class="hljs-selector-tag">server</span><br><span class="hljs-selector-attr">[root@admin ~]</span># <span class="hljs-selector-tag">systemctl</span> <span class="hljs-selector-tag">restart</span> <span class="hljs-selector-tag">ntpd</span><br><span class="hljs-selector-attr">[root@admin ~]</span># <span class="hljs-selector-tag">systemctl</span> <span class="hljs-selector-tag">enable</span> <span class="hljs-selector-tag">ntpd</span><br><span class="hljs-selector-tag">Created</span> <span class="hljs-selector-tag">symlink</span> <span class="hljs-selector-tag">from</span> /<span class="hljs-selector-tag">etc</span>/<span class="hljs-selector-tag">systemd</span>/<span class="hljs-selector-tag">system</span>/<span class="hljs-selector-tag">multi-user</span><span class="hljs-selector-class">.target</span><span class="hljs-selector-class">.wants</span>/<span class="hljs-selector-tag">ntpd</span><span class="hljs-selector-class">.service</span> <span class="hljs-selector-tag">to</span> /<span class="hljs-selector-tag">usr</span>/<span class="hljs-selector-tag">lib</span>/<span class="hljs-selector-tag">systemd</span>/<span class="hljs-selector-tag">system</span>/<span class="hljs-selector-tag">ntpd</span><span class="hljs-selector-class">.service</span>.<br><span class="hljs-selector-attr">[root@admin ~]</span># <span class="hljs-selector-tag">ntpq</span> <span class="hljs-selector-tag">-p</span><br>     <span class="hljs-selector-tag">remote</span>           <span class="hljs-selector-tag">refid</span>      <span class="hljs-selector-tag">st</span> <span class="hljs-selector-tag">t</span> <span class="hljs-keyword">when</span> poll reach   delay   offset  jitter<br>==============================================================================<br> <span class="hljs-number">120.25</span>.<span class="hljs-number">115.20</span>   <span class="hljs-number">10.137</span>.<span class="hljs-number">53.7</span>      <span class="hljs-number">2</span> u   <span class="hljs-number">46</span>   <span class="hljs-number">64</span>    <span class="hljs-number">3</span>    <span class="hljs-number">5.968</span>   -<span class="hljs-number">3.188</span>  <span class="hljs-number">19.905</span><br>*<span class="hljs-built_in">LOCAL</span>(<span class="hljs-number">0</span>)        .LOCL.           <span class="hljs-number">5</span> l   <span class="hljs-number">48</span>   <span class="hljs-number">64</span>    <span class="hljs-number">3</span>    <span class="hljs-number">0.000</span>    <span class="hljs-number">0.000</span>   <span class="hljs-number">0.000</span><br>[root<span class="hljs-variable">@admin</span> ~]#<br>[root<span class="hljs-variable">@admin</span> ~]# ntpstat<br>synchronised to local net (<span class="hljs-number">127.127</span>.<span class="hljs-number">1.0</span>) at stratum <span class="hljs-number">6</span><br>   time correct to within <span class="hljs-number">449</span> ms<br>   polling server every <span class="hljs-number">64</span> s<br>[root<span class="hljs-variable">@admin</span> ~]#<br><br><br>#ceph_node1节点配置<br>[root<span class="hljs-variable">@node1</span> ~]# grep <span class="hljs-number">142</span> /etc/ntp.conf<br>server <span class="hljs-number">192.168</span>.<span class="hljs-number">142.130</span>  #ceph_admin的ntp服务器<br>[root<span class="hljs-variable">@node1</span> ~]# systemctl restart ntpd<br>[root<span class="hljs-variable">@node1</span> ~]# systemctl enable ntpd<br>[root<span class="hljs-variable">@node1</span> ~]# ntpq -p<br>     remote           refid      st t <span class="hljs-keyword">when</span> poll reach   delay   offset  jitter<br>==============================================================================<br> ceph_admin      <span class="hljs-built_in">LOCAL</span>(<span class="hljs-number">0</span>)         <span class="hljs-number">6</span> u   <span class="hljs-number">56</span>   <span class="hljs-number">64</span>    <span class="hljs-number">3</span>    <span class="hljs-number">0.821</span>    <span class="hljs-number">3.245</span>   <span class="hljs-number">0.565</span><br><br><br>##ceph_node2节点配置<br>[root<span class="hljs-variable">@node2</span> ~]# grep <span class="hljs-number">142</span> /etc/ntp.conf<br>server <span class="hljs-number">192.168</span>.<span class="hljs-number">142.130</span>  ##ceph_admin的ntp服务器<br>[root<span class="hljs-variable">@node2</span> ~]# systemctl restart ntpd<br>[root<span class="hljs-variable">@node2</span> ~]# systemctl enable ntpd<br>[root<span class="hljs-variable">@node2</span> ~]# ntpq -p<br>     remote           refid      st t <span class="hljs-keyword">when</span> poll reach   delay   offset  jitter<br>==============================================================================<br> ceph_admin      <span class="hljs-built_in">LOCAL</span>(<span class="hljs-number">0</span>)         <span class="hljs-number">6</span> u   <span class="hljs-number">54</span>   <span class="hljs-number">64</span>    <span class="hljs-number">3</span>    <span class="hljs-number">0.871</span>   -<span class="hljs-number">0.474</span>   <span class="hljs-number">0.508</span><br><br><br><br>#ceph_node3节点配置<br>[root<span class="hljs-variable">@node3</span> ~]# grep <span class="hljs-number">142</span> /etc/ntp.conf<br>server <span class="hljs-number">192.168</span>.<span class="hljs-number">142.130</span>  #ceph_admin的ntp服务器<br>[root<span class="hljs-variable">@node3</span> ~]# systemctl restart ntpd<br>[root<span class="hljs-variable">@node3</span> ~]# systemctl enable ntpd<br>[root<span class="hljs-variable">@node3</span> ~]# ntpq -p<br>     remote           refid      st t <span class="hljs-keyword">when</span> poll reach   delay   offset  jitter<br>==============================================================================<br> ceph_admin      <span class="hljs-built_in">LOCAL</span>(<span class="hljs-number">0</span>)         <span class="hljs-number">6</span> u   <span class="hljs-number">53</span>   <span class="hljs-number">64</span>    <span class="hljs-number">3</span>    <span class="hljs-number">0.864</span>    <span class="hljs-number">1.155</span>   <span class="hljs-number">0.596</span><br><br></code></pre></td></tr></table></figure>

<h2 id="二、开始部署Ceph的集群"><a href="#二、开始部署Ceph的集群" class="headerlink" title="二、开始部署Ceph的集群"></a>二、开始部署Ceph的集群</h2><p><strong>1、修改yum源(所有节点进行)</strong></p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs autoit"><span class="hljs-meta">#ceph_node1 ceph_node2 ceph_node3以上三节点也需要执行以下步骤</span><br>[root<span class="hljs-symbol">@admin</span> ~]<span class="hljs-meta"># mkdir /mnt/repo_bak</span><br>[root<span class="hljs-symbol">@admin</span> ~]<span class="hljs-meta"># mv /etc/yum.repos.d/* /mnt/repo_bak/</span><br>[root<span class="hljs-symbol">@admin</span> ~]<span class="hljs-meta"># wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br>[root<span class="hljs-symbol">@admin</span> ~]<span class="hljs-meta"># wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><br><br></code></pre></td></tr></table></figure>

<p><strong>2、添加ceph的yum源(所有节点进行)</strong></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment"># cat /etc/yum.repos.d/ceph.repo</span><br><span class="hljs-section">[Ceph]</span><br><span class="hljs-attr">name</span>=Ceph<br><span class="hljs-attr">baseurl</span>=http://download.ceph.com/rpm-nautilus/el7/x<span class="hljs-number">86_64</span><br><span class="hljs-attr">enbaled</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">gpgcheck</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">type</span>=rpm-md<br><span class="hljs-attr">gpgkey</span>=https://download.ceph.com/keys/release.asc<br><span class="hljs-attr">priority</span>=<span class="hljs-number">1</span><br><br><span class="hljs-section">[Ceph-noarch]</span><br><span class="hljs-attr">name</span>=Ceph noarch packages<br><span class="hljs-attr">baseurl</span>=http://download.ceph.com/rpm-nautilus/el7/noarch<br><span class="hljs-attr">enabled</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">gpgcheck</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">type</span>=rpm-md<br><span class="hljs-attr">gpgkey</span>=https://download.ceph.com/keys/release.asc<br><span class="hljs-attr">priority</span>=<span class="hljs-number">1</span><br><br><span class="hljs-section">[Ceph-source]</span><br><span class="hljs-attr">name</span>=Ceph source packages<br><span class="hljs-attr">baseurl</span>=http://download.ceph.com/rpm-nautilus/el7/SRPMS<br><span class="hljs-attr">enabled</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">gpgcheck</span>=<span class="hljs-number">1</span><br><span class="hljs-attr">type</span>=rpm-md<br><span class="hljs-attr">gpgkey</span>=https://download.ceph.com/keys/release.asc<br><span class="hljs-attr">priority</span>=<span class="hljs-number">1</span><br><br><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment">#</span><br><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment"># yum makecache</span><br><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment"># yum update</span><br><br><br><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment"># scp /etc/yum.repos.d/ceph.repo root@ceph_node1:/etc/yum.repos.d/</span><br><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment"># scp /etc/yum.repos.d/ceph.repo root@ceph_node2:/etc/yum.repos.d/</span><br><span class="hljs-section">[root@admin ~]</span><span class="hljs-comment"># scp /etc/yum.repos.d/ceph.repo root@ceph_node3:/etc/yum.repos.d/</span><br><br><br></code></pre></td></tr></table></figure>

<p><strong>3、安装ceph-deploy(在ceph-admin节点上执行)</strong></p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">[root@<span class="hljs-keyword">admin</span> ~]# su - ceph-<span class="hljs-keyword">admin</span><br>Last <span class="hljs-keyword">login</span>: Wed Nov <span class="hljs-number">10</span> <span class="hljs-number">04</span>:<span class="hljs-number">18</span>:<span class="hljs-number">17</span> EST <span class="hljs-number">2021</span> <span class="hljs-keyword">on</span> pts/<span class="hljs-number">1</span><br>[ceph-<span class="hljs-keyword">admin</span>@<span class="hljs-keyword">admin</span> ~]$ sudo yum -y install python-setuptools<br>[ceph-<span class="hljs-keyword">admin</span>@<span class="hljs-keyword">admin</span> ~]$ sudo yum -y install ceph-deploy<br>[ceph-<span class="hljs-keyword">admin</span>@<span class="hljs-keyword">admin</span> ~]$ ceph-deploy <span class="hljs-comment">--version</span><br><span class="hljs-number">2.0</span><span class="hljs-number">.1</span><br></code></pre></td></tr></table></figure>

<p><strong>4、初始化集群(在ceph-node1节点上执行)</strong></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">#创建集群安装目录（ceph-deploy部署程序会将文件输出到当前目录）</span><br><span class="hljs-comment">#因为我是把ceph_node1节点作为mon监视器使用，所以规划中部署mon的节点ceph_node1</span><br><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy new ceph_node1<br>[ceph_deploy.conf][<span class="hljs-built_in">DEBUG</span> ] found configuration file at: /home/ceph-admin/.cephdeploy.conf<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ] Invoked (2.0.1): /bin/ceph-deploy new ceph_node1<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ] ceph-deploy options:<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  username                      : None<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  func                          : &lt;function new at 0x7fadd8b53d70&gt;<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  verbose                       : <span class="hljs-literal">False</span><br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  overwrite_conf                : <span class="hljs-literal">False</span><br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  quiet                         : <span class="hljs-literal">False</span><br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf<span class="hljs-built_in"> instance </span>at 0x7fadd82cc758&gt;<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  cluster                       : ceph<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  ssh_copykey                   : <span class="hljs-literal">True</span><br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  mon                           : [<span class="hljs-string">&#x27;ceph_node1&#x27;</span>]<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  public_network                : None<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  ceph_conf                     : None<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  cluster_network               : None<br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  default_release               : <span class="hljs-literal">False</span><br>[ceph_deploy.cli][<span class="hljs-built_in">INFO</span>  ]  fsid                          : None<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Creating new cluster named ceph<br>[ceph_deploy.new][<span class="hljs-built_in">INFO</span>  ] making sure passwordless SSH succeeds<br>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ] connected <span class="hljs-keyword">to</span> host: ceph_admin<br>[ceph_node1][<span class="hljs-built_in">INFO</span>  ] Running command: ssh -CT -o <span class="hljs-attribute">BatchMode</span>=<span class="hljs-literal">yes</span> ceph_node1<br>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ]<span class="hljs-built_in"> connection </span>detected need <span class="hljs-keyword">for</span> sudo<br>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ] connected <span class="hljs-keyword">to</span> host: ceph_node1<br>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ] detect platform information <span class="hljs-keyword">from</span> remote host<br>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ] detect machine<span class="hljs-built_in"> type</span><br><span class="hljs-built_in"></span>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ] <span class="hljs-built_in">find</span> the location of an executable<br>[ceph_node1][<span class="hljs-built_in">INFO</span>  ] Running command: sudo /usr/sbin<span class="hljs-built_in">/ip </span>link show<br>[ceph_node1][<span class="hljs-built_in">INFO</span>  ] Running command: sudo /usr/sbin<span class="hljs-built_in">/ip </span>addr show<br>[ceph_node1][<span class="hljs-built_in">DEBUG</span> ]<span class="hljs-built_in"> IP </span>addresses found: [u<span class="hljs-string">&#x27;192.168.241.134&#x27;</span>, u<span class="hljs-string">&#x27;192.168.142.134&#x27;</span>]<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Resolving host ceph_node1<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Monitor ceph_node1 at 192.168.142.134<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Monitor initial members are [<span class="hljs-string">&#x27;ceph_node1&#x27;</span>]<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Monitor addrs are [<span class="hljs-string">&#x27;192.168.142.134&#x27;</span>]<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Creating a random mon key<span class="hljs-built_in">..</span>.<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Writing monitor keyring <span class="hljs-keyword">to</span> ceph.mon.keyring<span class="hljs-built_in">..</span>.<br>[ceph_deploy.new][<span class="hljs-built_in">DEBUG</span> ] Writing initial<span class="hljs-built_in"> config </span><span class="hljs-keyword">to</span> ceph.conf<span class="hljs-built_in">..</span>.<br>[ceph-admin@ceph_admin cluster]$<br>[ceph-admin@ceph_admin cluster]$ ls<br>ceph.conf  ceph-deploy-ceph.log  ceph.mon.keyring<br>[ceph-admin@ceph_admin cluster]$<br><br><span class="hljs-comment">#在当前目录下的ceph.conf中添加以下两行内容</span><br>[ceph-admin@ceph_admin cluster]$ cat ceph.conf<br>public_network = 192.168.142.0/24<br>cluster_network = 192.168.241.0/24<br><br><span class="hljs-comment">#登录各个节点安装ceph</span><br><br>[ceph-admin@ceph_admin ~]$ ceph-deploy install --no-adjust-repos ceph_node1 ceph_node2 ceph_node3 <br><span class="hljs-comment">#每个节点需要安装提前安装sudo yum -y install python-setuptools</span><br><span class="hljs-comment">#如果安装不上可以直接sudo yum -y install ceph</span><br><br><span class="hljs-comment">#初始化mon的节点</span><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy mon create-initial<br><br><br><span class="hljs-comment">#将认证密钥拷贝到其他节点，便于ceph命令行可以通过keyring和ceph集群进行交互，其他节点主机也能管理ceph集群</span><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy admin ceph_node1 ceph_node2 ceph_node3<br><br></code></pre></td></tr></table></figure>

<p><strong>5、添加OSD硬盘</strong></p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">#查看节点上可以用的硬盘<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_admin <span class="hljs-keyword">cluster</span>]$ ceph-deploy disk list ceph_node1 ceph_node2 ceph_node3<br>#例如格式化ceph_node1 的/dev/sdb<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_admin <span class="hljs-keyword">cluster</span>]$ sudo ceph-deploy disk zap ceph_node1 /dev/sdb<br>[ceph_node1][WARNIN] <span class="hljs-comment">--&gt; Zapping successful for: &lt;Raw Device: /dev/sdb&gt;</span><br>#添加OSD<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_admin <span class="hljs-keyword">cluster</span>]$ ceph-deploy osd <span class="hljs-keyword">create</span> <span class="hljs-comment">--data /dev/sdb ceph_node1</span><br>[ceph-<span class="hljs-keyword">admin</span>@ceph_admin <span class="hljs-keyword">cluster</span>]$ ceph-deploy osd <span class="hljs-keyword">create</span> <span class="hljs-comment">--data /dev/sdb ceph_node2</span><br>[ceph-<span class="hljs-keyword">admin</span>@ceph_admin <span class="hljs-keyword">cluster</span>]$ ceph-deploy osd <span class="hljs-keyword">create</span> <span class="hljs-comment">--data /dev/sdb ceph_node3</span><br>#可以看到ceph将新增osd创建文LVM格式加入ceph集群中<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node3 ~]$ sudo pvs<br>  PV         VG                                        Fmt  Attr PSize   PFree<br>  /dev/sda2  centos                                    lvm2 a<span class="hljs-comment">--  &lt;19.00g    0</span><br>  /dev/sdb   ceph<span class="hljs-number">-51501953</span><span class="hljs-number">-9</span>a57<span class="hljs-number">-4</span>f58-bcda<span class="hljs-number">-8</span>a9a2d8ab6e0 lvm2 a<span class="hljs-comment">--  &lt;10.00g    0</span><br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node3 ~]$<br><br></code></pre></td></tr></table></figure>
<p><strong>6、部署MGR用于获</strong></p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment">#部署MGR用于获取集群信息</span><br>(<span class="hljs-built_in">reverse</span>-i-search)`creat&#x27;: ceph-deploy mgr create ceph_node1<br></code></pre></td></tr></table></figure>

<p><img src="/img/Linux/osd.png" srcset="/img/loading.gif"></p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs dts">如果发现sudo ceph -s 出现health:HEALTH_WARN 的情况下需要 禁用掉不安全的模式<br>[ceph-admin@ceph_node1 ~]$ sudo ceph config set mon auth_allow_insecure_global_id_reclaim false<br><span class="hljs-meta">#查看集群的状态</span><br>[ceph-admin@ceph_node1 ~]$ sudo ceph -s<br><span class="hljs-symbol">  cluster:</span><br><span class="hljs-symbol">    id:</span>     <span class="hljs-number">04</span>af08e4<span class="hljs-number">-3541</span><span class="hljs-number">-4448</span>-b7b3-f456e1302083<br><span class="hljs-symbol">    health:</span> HEALTH_OK<br><span class="hljs-symbol"></span><br><span class="hljs-symbol">  services:</span><br><span class="hljs-symbol">    mon:</span> <span class="hljs-number">1</span> daemons, quorum ceph_node1 (age <span class="hljs-number">3</span>h)<br><span class="hljs-symbol">    mgr:</span> ceph_node1(active, since <span class="hljs-number">44</span>m)<br><span class="hljs-symbol">    osd:</span> <span class="hljs-number">3</span> osds: <span class="hljs-number">3</span> up (since <span class="hljs-number">54</span>m), <span class="hljs-number">3</span> in (since <span class="hljs-number">54</span>m)<br><span class="hljs-symbol"></span><br><span class="hljs-symbol">  data:</span><br><span class="hljs-symbol">    pools:</span>   <span class="hljs-number">0</span> pools, <span class="hljs-number">0</span> pgs<br><span class="hljs-symbol">    objects:</span> <span class="hljs-number">0</span> objects, <span class="hljs-number">0</span> B<br><span class="hljs-symbol">    usage:</span>   <span class="hljs-number">3.0</span> GiB used, <span class="hljs-number">27</span> GiB / <span class="hljs-number">30</span> GiB avail<br><span class="hljs-symbol">    pgs:</span><br><br>[ceph-admin@ceph_node1 ~]$<br><br>因<span class="hljs-keyword">/etc/</span>ceph/下key文件普通用户没有读权限，所以普通用户无权直接执行ceph命令<br>如果需要ceph-admin普通用户也可直接调用集群，增加对ceph配置文件的读权限即可<br>（想要每个节点普通用户都可以执行ceph相关命令，那就所有节点都修改权限）<br></code></pre></td></tr></table></figure>

<p><strong>7、修改普通用户ceph-admin有调用集群的权限</strong></p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs dts">[ceph-admin@ceph_node1 ~]$ sudo chmod +r <span class="hljs-keyword">/etc/</span>ceph/ceph.client.admin.keyring<br>[ceph-admin@ceph_node1 ~]$ ceph -s<br><span class="hljs-symbol">  cluster:</span><br><span class="hljs-symbol">    id:</span>     <span class="hljs-number">04</span>af08e4<span class="hljs-number">-3541</span><span class="hljs-number">-4448</span>-b7b3-f456e1302083<br><span class="hljs-symbol">    health:</span> HEALTH_OK<br><span class="hljs-symbol"></span><br><span class="hljs-symbol">  services:</span><br><span class="hljs-symbol">    mon:</span> <span class="hljs-number">1</span> daemons, quorum ceph_node1 (age <span class="hljs-number">3</span>h)<br><span class="hljs-symbol">    mgr:</span> ceph_node1(active, since <span class="hljs-number">54</span>m)<br><span class="hljs-symbol">    osd:</span> <span class="hljs-number">3</span> osds: <span class="hljs-number">3</span> up (since <span class="hljs-number">64</span>m), <span class="hljs-number">3</span> in (since <span class="hljs-number">64</span>m)<br><span class="hljs-symbol"></span><br><span class="hljs-symbol">  data:</span><br><span class="hljs-symbol">    pools:</span>   <span class="hljs-number">0</span> pools, <span class="hljs-number">0</span> pgs<br><span class="hljs-symbol">    objects:</span> <span class="hljs-number">0</span> objects, <span class="hljs-number">0</span> B<br><span class="hljs-symbol">    usage:</span>   <span class="hljs-number">3.0</span> GiB used, <span class="hljs-number">27</span> GiB / <span class="hljs-number">30</span> GiB avail<br><span class="hljs-symbol">    pgs:</span><br><br>[ceph-admin@ceph_node1 ~]$<br><br></code></pre></td></tr></table></figure>

<h2 id="三、配置Mgr-Dashboard模块"><a href="#三、配置Mgr-Dashboard模块" class="headerlink" title="三、配置Mgr-Dashboard模块"></a>三、配置Mgr-Dashboard模块</h2><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-comment">#安装ceph-mgr-dashboard，在mgr的节点上安装</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">sudo</span> <span class="hljs-string">yum</span> -<span class="hljs-string">y</span> <span class="hljs-string">install</span> <span class="hljs-string">ceph-mgr-dashboard</span><br><span class="hljs-comment">#开启mgr的dashboard模块</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">sudo</span> <span class="hljs-string">ceph</span> <span class="hljs-string">mgr</span> <span class="hljs-string">module</span> <span class="hljs-string">enable</span> <span class="hljs-string">dashboard</span><br><span class="hljs-comment">#默认情况下，仪表板的所有HTTP连接均使用SSL/TLS进行保护，快速启动并运行仪表板，可以使用以下命令生成并安装自签名证书</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">sudo</span> <span class="hljs-string">ceph</span> <span class="hljs-string">dashboard</span> <span class="hljs-built_in">create-self-signed-cert</span><br><span class="hljs-string">Self-signed</span> <span class="hljs-string">certificate</span> <span class="hljs-string">created</span><br><br><span class="hljs-comment">#创建具有管理员角色的用户：</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">sudo</span> <span class="hljs-string">ceph</span> <span class="hljs-string">dashboard</span> <span class="hljs-built_in">set-login-credentials</span> <span class="hljs-string">admin</span> <span class="hljs-string">admin</span><br><span class="hljs-string">Invalid</span> <span class="hljs-string">command</span>: <span class="hljs-string">unused</span> <span class="hljs-string">arguments</span>: [<span class="hljs-string">u</span><span class="hljs-string">&#x27;admin&#x27;</span>]<br><span class="hljs-string">dashboard</span> <span class="hljs-built_in">set-login-credentials</span> &lt;<span class="hljs-string">username</span>&gt; :  <span class="hljs-string">Set</span> <span class="hljs-string">the</span> <span class="hljs-string">login</span> <span class="hljs-string">credentials</span>. <span class="hljs-string">Password</span> <span class="hljs-string">read</span> <span class="hljs-string">from</span> -<span class="hljs-string">i</span> &lt;<span class="hljs-string">file</span>&gt;<br><span class="hljs-string">Error</span> <span class="hljs-string">EINVAL</span>: <span class="hljs-string">invalid</span> <span class="hljs-string">command</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$<br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">ls</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">vim</span> <span class="hljs-string">userpass</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">sudo</span> <span class="hljs-string">vim</span> <span class="hljs-string">userpass</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$<br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$<br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">sudo</span> <span class="hljs-string">ceph</span> <span class="hljs-string">dashboard</span> <span class="hljs-built_in">set-login-credentials</span> <span class="hljs-string">Narwal-admin</span> -<span class="hljs-string">i</span> <span class="hljs-string">userpass</span><br>******************************************************************<br>***          <span class="hljs-string">WARNING</span>: <span class="hljs-string">this</span> <span class="hljs-string">command</span> <span class="hljs-string">is</span> <span class="hljs-string">deprecated</span>.              ***<br>*** <span class="hljs-string">Please</span> <span class="hljs-string">use</span> <span class="hljs-string">the</span> <span class="hljs-string">ac-user</span>-* <span class="hljs-string">related</span> <span class="hljs-string">commands</span> <span class="hljs-string">to</span> <span class="hljs-string">manage</span> <span class="hljs-string">users</span>. ***<br>******************************************************************<br><span class="hljs-string">Username</span> <span class="hljs-string">and</span> <span class="hljs-string">password</span> <span class="hljs-string">updated</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$<br><br><br><span class="hljs-comment">#查看ceph-mgr的服务:</span><br>[<span class="hljs-string">ceph-admin</span>@<span class="hljs-string">ceph_node1</span> ~]$ <span class="hljs-string">ceph</span> <span class="hljs-string">mgr</span> <span class="hljs-string">services</span><br>&#123;<br>    <span class="hljs-string">&quot;dashboard&quot;</span>: <span class="hljs-string">&quot;https://ceph_node1:8443/&quot;</span><br>&#125;<br><br></code></pre></td></tr></table></figure>
<p><img src="/img/Linux/dashboard.png" srcset="/img/loading.gif"></p>
<h2 id="四、新增服务器实现扩容"><a href="#四、新增服务器实现扩容" class="headerlink" title="四、新增服务器实现扩容"></a>四、新增服务器实现扩容</h2><p><img src="/img/Linux/ceph_info2.png" srcset="/img/loading.gif"></p>
<p><strong>1、进行基本的配置</strong></p>
<figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs perl"><span class="hljs-comment">#关闭防火墙和selinu(扩容节点进行)</span><br><br>[root@ceph_node4 ~]<span class="hljs-comment"># systemctl stop firewalld</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># systemctl disable firewalld</span><br>Removed <span class="hljs-keyword">symlink</span> /etc/systemd/<span class="hljs-keyword">system</span>/multi-user.target.wants/firewalld.service.<br>Removed <span class="hljs-keyword">symlink</span> /etc/systemd/<span class="hljs-keyword">system</span>/dbus-org.fedoraproject.FirewallD1.service.<br>[root@ceph_node4 ~]<span class="hljs-comment">#</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># sed -i &quot;s/SELINUX=enforcing/SELINUX=permissive/g&quot; /etc/selinux/config</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># getenforce</span><br>Enforcing<br>[root@ceph_node4 ~]<span class="hljs-comment"># setenforce 0</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># getenforce</span><br>Permissive<br>[root@ceph_node4 ~]<span class="hljs-comment">#</span><br><br><span class="hljs-comment">#配置hosts所有节点进行</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># cat /etc/hosts</span><br><span class="hljs-number">127.0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>   localhost localhost.localdomain localhost4 localhost4.localdomain<br>::<span class="hljs-number">1</span>         localhost localhost.localdomain localhost6 localhost6.localdomain6<br><span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span> ceph_node1<br><span class="hljs-number">192.168</span>.<span class="hljs-number">142.135</span> ceph_node2<br><span class="hljs-number">192.168</span>.<span class="hljs-number">142.136</span> ceph_node3<br><span class="hljs-number">192.168</span>.<span class="hljs-number">142.137</span> ceph_node4<br>[root@ceph_node4 ~]<span class="hljs-comment">#</span><br><br><br><span class="hljs-comment">#添加ceph-admin的账户</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># useradd ceph-admin</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># echo &quot;Lemon/123&quot; | passwd --stdin ceph-admin</span><br>Changing password <span class="hljs-keyword">for</span> user ceph-admin.<br>passwd: all authentication tokens updated successfully.<br>[root@ceph_node4 ~]<span class="hljs-comment"># echo &quot;ceph-admin ALL = NOPASSWD:ALL&quot; | tee /etc/sudoers.d/ceph-admin</span><br>ceph-admin ALL = NOPASSWD:ALL<br>[root@ceph_node4 ~]<span class="hljs-comment"># chmod 0400 /etc/sudoers.d/ceph-admin</span><br>[root@ceph_node4 ~]<span class="hljs-comment">#</span><br><br><span class="hljs-comment">#安装ntp并与ceph-admin服务器连接</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># yum -y install ntp</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># cat  /etc/ntp.conf | grep 130</span><br>server <span class="hljs-number">192.168</span>.<span class="hljs-number">142.130</span>  <span class="hljs-comment">#ceph-admin的ntp服务器</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># systemctl restart ntpd</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># systemctl enable ntpd</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># ntpq -p</span><br>     remote           refid      st t <span class="hljs-keyword">when</span> poll reach   delay   offset  jitter<br>==============================================================================<br> <span class="hljs-number">192.168</span>.<span class="hljs-number">142.130</span> <span class="hljs-number">120.25</span>.<span class="hljs-number">115.20</span>    <span class="hljs-number">3</span> u   <span class="hljs-number">16</span>   <span class="hljs-number">64</span>    <span class="hljs-number">1</span>    <span class="hljs-number">1.007</span>    <span class="hljs-number">1.223</span>   <span class="hljs-number">0</span>.<span class="hljs-number">000</span><br><br><br><span class="hljs-comment">#配置yum源</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># mkdir /mnt/repo_bak</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># mv /etc/yum.repos.d/* /mnt/repo_bak/</span><br>[root@ceph_node4 ~]<span class="hljs-comment">#</span><br>[root@ceph_node3 ~]<span class="hljs-comment"># scp /etc/yum.repos.d/* root@ceph_node4:/etc/yum.repos.d/</span><br></code></pre></td></tr></table></figure>

<p><strong>2、进行对增加的机器扩容</strong></p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment">#安装ceph</span><br>[ceph-admin@ceph_node4 yum.repos.d]$ sudo yum -y install ceph ceph-radosgw<br><span class="hljs-comment">#扫描硬盘</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host0/scan</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host1/scan</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host2/scan</span><br>[root@ceph_node4 ~]<span class="hljs-comment">#</span><br>[root@ceph_node4 ~]<span class="hljs-comment"># lsblk</span><br>NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT<br>sda               8:0   <span class="hljs-number"> 0 </span>  20G <span class="hljs-number"> 0 </span>disk<br>├─sda1            8:1   <span class="hljs-number"> 0 </span>   1G <span class="hljs-number"> 0 </span>part /boot<br>└─sda2            8:2   <span class="hljs-number"> 0 </span>  19G <span class="hljs-number"> 0 </span>part<br>  ├─centos-root 253:0   <span class="hljs-number"> 0 </span>  17G <span class="hljs-number"> 0 </span>lvm  /<br>  └─centos-swap 253:1   <span class="hljs-number"> 0 </span>   2G <span class="hljs-number"> 0 </span>lvm  [SWAP]<br>sdb               8:16  <span class="hljs-number"> 0 </span>  10G <span class="hljs-number"> 0 </span>disk<br>sr0              11:0   <span class="hljs-number"> 1 </span>1024M <span class="hljs-number"> 0 </span>rom<br><br><span class="hljs-comment">#查看当前osd集群</span><br>[ceph-admin@ceph_node1 ~]$ ceph osd stat<br>3 osds:<span class="hljs-number"> 3 </span>up (since 23h),<span class="hljs-number"> 3 </span>in (since 23h); epoch: e1<br><span class="hljs-comment">#格式化硬盘</span><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy disk zap ceph_node4 /dev/sdb<br><span class="hljs-comment">#将新增的节点的硬盘加入到集群osd当中</span><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy osd create --data /dev/sdb ceph_node4<br><span class="hljs-comment">#查看加入后的osd集群</span><br>[ceph-admin@ceph_node1 ~]$ ceph osd stat<br>4 osds:<span class="hljs-number"> 4 </span>up (since 8s),<span class="hljs-number"> 4 </span>in (since 8s); epoch: e17<br><br></code></pre></td></tr></table></figure>

<p><strong>3、进行对新增加的硬盘实现扩容</strong></p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs gradle">#识别硬盘当前服务器的硬盘<br>[root@ceph_node4 ~]# sudo echo <span class="hljs-string">&quot;- - -&quot;</span> &gt; <span class="hljs-regexp">/sys/</span><span class="hljs-keyword">class</span><span class="hljs-regexp">/scsi_host/</span>host0/scan<br>[root@ceph_node4 ~]# sudo echo <span class="hljs-string">&quot;- - -&quot;</span> &gt; <span class="hljs-regexp">/sys/</span><span class="hljs-keyword">class</span><span class="hljs-regexp">/scsi_host/</span>host1/scan<br>[root@ceph_node4 ~]# sudo echo <span class="hljs-string">&quot;- - -&quot;</span> &gt; <span class="hljs-regexp">/sys/</span><span class="hljs-keyword">class</span><span class="hljs-regexp">/scsi_host/</span>host2/scan<br>#查看硬盘空间<br>[ceph-admin@ceph_admin cluster]$ ceph-deploy disk list ceph_node4<br>[ceph_node4][INFO  ] Disk <span class="hljs-regexp">/dev/</span>sdc: <span class="hljs-number">10.7</span> GB, <span class="hljs-number">10737418240</span> bytes, <span class="hljs-number">20971520</span> sectors<br>#格式化硬盘<br>[ceph-admin@ceph_admin cluster]$ ceph-deploy disk zap ceph_node4 <span class="hljs-regexp">/dev/</span>sdc<br>[ceph_node4][WARNIN] --&gt; Zapping successful <span class="hljs-keyword">for</span>: &lt;Raw Device: <span class="hljs-regexp">/dev/</span>sdc&gt;<br>#将该硬盘添加进osd空间<br>[ceph-admin@ceph_admin cluster]$ ceph-deploy osd create --data <span class="hljs-regexp">/dev/</span>sdc ceph_node4<br>#查看集群的状态<br>[ceph-admin@ceph_node1 ~]$ ceph osd stat<br><span class="hljs-number">5</span> osds: <span class="hljs-number">5</span> up (since <span class="hljs-number">108</span>s), <span class="hljs-number">5</span> in (since <span class="hljs-number">108</span>s); epoch: e21<br></code></pre></td></tr></table></figure>

<p><strong>4、创建Pool的资源池</strong></p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">#创建一个名称叫ceph_demo pg是<span class="hljs-number">64</span>  pgp是<span class="hljs-number">64</span>的<br>[root@ceph_node1 ~]# ceph osd pool <span class="hljs-keyword">create</span> ceph-demo <span class="hljs-number">64</span> <span class="hljs-number">64</span><br>#查看pool池是否创建成功<br>[root@ceph_node1 ~]# ceph osd lspools<br><span class="hljs-number">1</span> ceph-demo<br><br>#另外<br>#可以将副本调整为<span class="hljs-number">3</span>个或者<span class="hljs-number">2</span>个<br>[root@ceph_node1 ~]# ceph osd pool <span class="hljs-keyword">get</span> ceph-demo size<br>size: <span class="hljs-number">2</span><br>[root@ceph_node1 ~]# ceph osd pool <span class="hljs-keyword">set</span> ceph-demo size <span class="hljs-number">3</span><br>#可以修改pg_num 或者 pgp_num<br>[root@ceph_node1 ~]# ceph osd pool <span class="hljs-keyword">get</span> ceph-demo pg_num<br>pg_num: <span class="hljs-number">128</span><br>[root@ceph_node1 ~]#<br>[root@ceph_node1 ~]# ceph osd pool <span class="hljs-keyword">set</span> ceph-demo pgp_num <span class="hljs-number">128</span><br><span class="hljs-keyword">set</span> pool <span class="hljs-number">1</span> pgp_num <span class="hljs-keyword">to</span> <span class="hljs-number">128</span><br>[root@ceph_node1 ~]# ceph osd pool <span class="hljs-keyword">get</span> ceph-demo pgp_num<br>pgp_num: <span class="hljs-number">128</span><br>[root@ceph_node1 ~]#<br></code></pre></td></tr></table></figure>

<p><strong>5、RBD的块设备存储创建、映射、扩容</strong></p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment">#创建一个image大小为1G的文件</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd create -p ceph-demo --image rbd-demo.img --size 1G</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd -p ceph-demo ls</span><br>rbd-demo.img<br><span class="hljs-comment">#查看ceph-demo下的img的信息</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd info ceph-demo/rbd-demo.img</span><br>rbd image <span class="hljs-string">&#x27;rbd-demo.img&#x27;</span>:<br>        size <span class="hljs-number">1</span> GiB in <span class="hljs-number">256</span> objects<br>        order <span class="hljs-number">22</span> (<span class="hljs-number">4</span> MiB objects)<br>        <span class="hljs-symbol">snapshot_count:</span> <span class="hljs-number">0</span><br>        <span class="hljs-symbol">id:</span> <span class="hljs-number">115e</span>d393ae63<br>        <span class="hljs-symbol">block_name_prefix:</span> rbd_data.<span class="hljs-number">115e</span>d393ae63<br>        <span class="hljs-symbol">format:</span> <span class="hljs-number">2</span><br>        <span class="hljs-symbol">features:</span> layering, exclusive-lock, object-map, fast-diff, deep-flatten<br>        <span class="hljs-symbol">op_features:</span><br>        <span class="hljs-symbol">flags:</span><br>        <span class="hljs-symbol">create_timestamp:</span> Thu Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>4:<span class="hljs-number">32</span>:<span class="hljs-number">50</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">access_timestamp:</span> Thu Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>4:<span class="hljs-number">32</span>:<span class="hljs-number">50</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">modify_timestamp:</span> Thu Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>4:<span class="hljs-number">32</span>:<span class="hljs-number">50</span> <span class="hljs-number">2021</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment">#</span><br><span class="hljs-comment">#可以删除img镜像</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd rm -p ceph-demo --image rbd-demo.img</span><br><br><span class="hljs-comment">#挂载设备</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd map ceph-demo/rbd-demo.img</span><br><span class="hljs-symbol">rbd:</span> sysfs write failed<br>RBD image feature set mismatch. You can disable features unsupported by the kernel <span class="hljs-keyword">with</span> <span class="hljs-string">&quot;rbd feature disable ceph-demo/rbd-demo.img object-map fast-diff deep-flatten&quot;</span>.<br>In some cases useful info is found in syslog - try <span class="hljs-string">&quot;dmesg | tail&quot;</span>.<br><span class="hljs-symbol">rbd:</span> map <span class="hljs-symbol">failed:</span> (<span class="hljs-number">6</span>) No such device or address<br><span class="hljs-comment">#可以根据提示禁用以下features</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd feature disable ceph-demo/rbd-demo.img object-map fast-diff deep-flatten</span><br><span class="hljs-comment">#重新挂载块设备</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment">#  rbd map ceph-demo/rbd-demo.img</span><br><span class="hljs-regexp">/dev/rbd</span>0<br><span class="hljs-comment">#查看块设备挂载的情况</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># rbd device list</span><br>id pool      namespace image        snap device<br><span class="hljs-number">0</span>  ceph-demo           rbd-demo.img -    <span class="hljs-regexp">/dev/rbd</span>0<br><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># fdisk -l | grep /dev/rbd0</span><br>Disk /dev/<span class="hljs-symbol">rbd0:</span> <span class="hljs-number">1073</span> MB, <span class="hljs-number">1073741824</span> bytes, <span class="hljs-number">2097152</span> sectors<br><span class="hljs-comment">#格式化分区</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># mkfs.ext4 /dev/rbd0</span><br><span class="hljs-comment">#新建一个文件夹然后挂载</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># mkdir /mnt/rbd-demo</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># mount /dev/rbd0 /mnt/rbd-demo/</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># df -Th</span><br>Filesystem              Type      Size  Used Avail Use% Mounted on<br>devtmpfs                devtmpfs  <span class="hljs-number">898</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">898</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/dev</span><br><span class="hljs-regexp">tmpfs                   tmpfs     910M     0  910M   0% /dev</span><span class="hljs-regexp">/shm</span><br><span class="hljs-regexp">tmpfs                   tmpfs     910M   33M  878M   4% /run</span><br>tmpfs                   tmpfs     <span class="hljs-number">910</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">910</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/sys/fs</span><span class="hljs-regexp">/cgroup</span><br><span class="hljs-regexp">/dev</span><span class="hljs-regexp">/mapper/centos</span>-root xfs        <span class="hljs-number">17</span>G  <span class="hljs-number">2.8</span>G   <span class="hljs-number">15</span>G  <span class="hljs-number">17</span>% <span class="hljs-regexp">/</span><br><span class="hljs-regexp">/dev</span><span class="hljs-regexp">/sda1               xfs      1014M  176M  839M  18% /boot</span><br>tmpfs                   tmpfs     <span class="hljs-number">910</span>M   <span class="hljs-number">52</span>K  <span class="hljs-number">910</span>M   <span class="hljs-number">1</span>% <span class="hljs-regexp">/var/lib</span><span class="hljs-regexp">/ceph/osd</span><span class="hljs-regexp">/ceph-0</span><br><span class="hljs-regexp">tmpfs                   tmpfs     182M     0  182M   0% /run</span><span class="hljs-regexp">/user/</span><span class="hljs-number">0</span><br><span class="hljs-regexp">/dev/rbd</span>0               ext4      <span class="hljs-number">976</span>M  <span class="hljs-number">2.6</span>M  <span class="hljs-number">907</span>M   <span class="hljs-number">1</span>% <span class="hljs-regexp">/mnt/rbd</span>-demo<br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment">#</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment"># touch test</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment"># ll</span><br>total <span class="hljs-number">16</span><br>drwx------. <span class="hljs-number">2</span> root root <span class="hljs-number">16384</span> Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>5:<span class="hljs-number">29</span> lost+found<br>-rw-r--r--. <span class="hljs-number">1</span> root root     <span class="hljs-number">0</span> Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>5:<span class="hljs-number">31</span> test<br><br><span class="hljs-comment">##块设备的扩容</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment"># rbd resize ceph-demo/rbd-demo.img --size 2G</span><br>Resizing <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment">#</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment"># rbd -p ceph-demo info --image rbd-demo.img</span><br>rbd image <span class="hljs-string">&#x27;rbd-demo.img&#x27;</span>:<br>        size <span class="hljs-number">2</span> GiB in <span class="hljs-number">512</span> objects<br>        order <span class="hljs-number">22</span> (<span class="hljs-number">4</span> MiB objects)<br>        <span class="hljs-symbol">snapshot_count:</span> <span class="hljs-number">0</span><br>        <span class="hljs-symbol">id:</span> <span class="hljs-number">115e</span>d393ae63<br>        <span class="hljs-symbol">block_name_prefix:</span> rbd_data.<span class="hljs-number">115e</span>d393ae63<br>        <span class="hljs-symbol">format:</span> <span class="hljs-number">2</span><br>        <span class="hljs-symbol">features:</span> layering, exclusive-lock<br>        <span class="hljs-symbol">op_features:</span><br>        <span class="hljs-symbol">flags:</span><br>        <span class="hljs-symbol">create_timestamp:</span> Thu Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>4:<span class="hljs-number">32</span>:<span class="hljs-number">50</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">access_timestamp:</span> Thu Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>4:<span class="hljs-number">32</span>:<span class="hljs-number">50</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">modify_timestamp:</span> Thu Nov <span class="hljs-number">18</span> <span class="hljs-number">0</span>4:<span class="hljs-number">32</span>:<span class="hljs-number">50</span> <span class="hljs-number">2021</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment">#</span><br><span class="hljs-comment">#块设备扩容成功后,再次进行对文件系统的扩容。</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment"># resize2fs /dev/rbd0</span><br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment"># df -Th | grep /dev/rbd0</span><br><span class="hljs-regexp">/dev/rbd</span>0               ext4      <span class="hljs-number">2.0</span>G  <span class="hljs-number">3.0</span>M  <span class="hljs-number">1.9</span>G   <span class="hljs-number">1</span>% <span class="hljs-regexp">/mnt/rbd</span>-demo<br>[root<span class="hljs-variable">@ceph_node1</span> rbd-demo]<span class="hljs-comment">#</span><br><br><br><span class="hljs-comment">#rbg数据存储的一个过程是,一个文件会被切割成多个对象,而多个对象会被不同写入到不同的pg,pg在存储到不同的osd上的一个过程。</span><br><br></code></pre></td></tr></table></figure>

<p><strong>6、ceph告警设备的排查</strong></p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment">#可以查看到当前health是WRARN</span><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment"># ceph -s</span><br>  <span class="hljs-attr">cluster:</span><br>    <span class="hljs-attr">id:</span>     <span class="hljs-string">04af08e4-3541-4448-b7b3-f456e1302083</span><br>    <span class="hljs-attr">health:</span> <span class="hljs-string">HEALTH_WARN</span><br>            <span class="hljs-string">application</span> <span class="hljs-string">not</span> <span class="hljs-string">enabled</span> <span class="hljs-string">on</span> <span class="hljs-number">1</span> <span class="hljs-string">pool(s)</span><br><br>  <span class="hljs-attr">services:</span><br>    <span class="hljs-attr">mon:</span> <span class="hljs-number">1</span> <span class="hljs-string">daemons,</span> <span class="hljs-string">quorum</span> <span class="hljs-string">ceph_node1</span> <span class="hljs-string">(age</span> <span class="hljs-string">7d)</span><br>    <span class="hljs-attr">mgr:</span> <span class="hljs-string">ceph_node1(active,</span> <span class="hljs-string">since</span> <span class="hljs-string">6d)</span><br>    <span class="hljs-attr">osd: 5 osds:</span> <span class="hljs-number">5</span> <span class="hljs-string">up</span> <span class="hljs-string">(since</span> <span class="hljs-string">3d),</span> <span class="hljs-number">5</span> <span class="hljs-string">in</span> <span class="hljs-string">(since</span> <span class="hljs-string">3d)</span><br><br>  <span class="hljs-attr">data:</span><br>    <span class="hljs-attr">pools:</span>   <span class="hljs-number">1</span> <span class="hljs-string">pools,</span> <span class="hljs-number">128</span> <span class="hljs-string">pgs</span><br>    <span class="hljs-attr">objects:</span> <span class="hljs-number">21</span> <span class="hljs-string">objects,</span> <span class="hljs-number">38</span> <span class="hljs-string">MiB</span><br>    <span class="hljs-attr">usage:</span>   <span class="hljs-number">5.2</span> <span class="hljs-string">GiB</span> <span class="hljs-string">used,</span> <span class="hljs-number">45</span> <span class="hljs-string">GiB</span> <span class="hljs-string">/</span> <span class="hljs-number">50</span> <span class="hljs-string">GiB</span> <span class="hljs-string">avail</span><br>    <span class="hljs-attr">pgs:</span>     <span class="hljs-number">128</span> <span class="hljs-string">active+clean</span><br><br><span class="hljs-comment"># 查看详细ceph健康信息</span><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment"># ceph health detail</span><br><span class="hljs-string">HEALTH_WARN</span> <span class="hljs-string">application</span> <span class="hljs-string">not</span> <span class="hljs-string">enabled</span> <span class="hljs-string">on</span> <span class="hljs-number">1</span> <span class="hljs-string">pool(s)</span><br><span class="hljs-string">POOL_APP_NOT_ENABLED</span> <span class="hljs-string">application</span> <span class="hljs-string">not</span> <span class="hljs-string">enabled</span> <span class="hljs-string">on</span> <span class="hljs-number">1</span> <span class="hljs-string">pool(s)</span><br>    <span class="hljs-string">application</span> <span class="hljs-string">not</span> <span class="hljs-string">enabled</span> <span class="hljs-string">on</span> <span class="hljs-string">pool</span> <span class="hljs-string">&#x27;ceph-demo&#x27;</span><br>    <span class="hljs-string">use</span> <span class="hljs-string">&#x27;ceph osd pool application enable &lt;pool-name&gt; &lt;app-name&gt;&#x27;</span><span class="hljs-string">,</span> <span class="hljs-string">where</span> <span class="hljs-string">&lt;app-name&gt;</span> <span class="hljs-string">is</span> <span class="hljs-string">&#x27;cephfs&#x27;</span><span class="hljs-string">,</span> <span class="hljs-string">&#x27;rbd&#x27;</span><span class="hljs-string">,</span> <span class="hljs-string">&#x27;rgw&#x27;</span><span class="hljs-string">,</span> <span class="hljs-string">or</span> <span class="hljs-string">freeform</span> <span class="hljs-string">for</span> <span class="hljs-string">custom</span> <span class="hljs-string">applications.</span><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment">#</span><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment">#</span><br><span class="hljs-comment">#启用application的rbd后告警显示消除</span><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment"># ceph osd pool application enable ceph-demo rbd</span><br><span class="hljs-string">enabled</span> <span class="hljs-string">application</span> <span class="hljs-string">&#x27;rbd&#x27;</span> <span class="hljs-string">on</span> <span class="hljs-string">pool</span> <span class="hljs-string">&#x27;ceph-demo&#x27;</span><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment"># ceph osd pool application get ceph-demo</span><br>&#123;<br>    <span class="hljs-attr">&quot;rbd&quot;:</span> &#123;&#125;<br>&#125;<br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment"># ceph -s</span><br>  <span class="hljs-attr">cluster:</span><br>    <span class="hljs-attr">id:</span>     <span class="hljs-string">04af08e4-3541-4448-b7b3-f456e1302083</span><br>    <span class="hljs-attr">health:</span> <span class="hljs-string">HEALTH_OK</span><br><br>  <span class="hljs-attr">services:</span><br>    <span class="hljs-attr">mon:</span> <span class="hljs-number">1</span> <span class="hljs-string">daemons,</span> <span class="hljs-string">quorum</span> <span class="hljs-string">ceph_node1</span> <span class="hljs-string">(age</span> <span class="hljs-string">7d)</span><br>    <span class="hljs-attr">mgr:</span> <span class="hljs-string">ceph_node1(active,</span> <span class="hljs-string">since</span> <span class="hljs-string">6d)</span><br>    <span class="hljs-attr">osd: 5 osds:</span> <span class="hljs-number">5</span> <span class="hljs-string">up</span> <span class="hljs-string">(since</span> <span class="hljs-string">3d),</span> <span class="hljs-number">5</span> <span class="hljs-string">in</span> <span class="hljs-string">(since</span> <span class="hljs-string">3d)</span><br><br>  <span class="hljs-attr">data:</span><br>    <span class="hljs-attr">pools:</span>   <span class="hljs-number">1</span> <span class="hljs-string">pools,</span> <span class="hljs-number">128</span> <span class="hljs-string">pgs</span><br>    <span class="hljs-attr">objects:</span> <span class="hljs-number">21</span> <span class="hljs-string">objects,</span> <span class="hljs-number">38</span> <span class="hljs-string">MiB</span><br>    <span class="hljs-attr">usage:</span>   <span class="hljs-number">5.2</span> <span class="hljs-string">GiB</span> <span class="hljs-string">used,</span> <span class="hljs-number">45</span> <span class="hljs-string">GiB</span> <span class="hljs-string">/</span> <span class="hljs-number">50</span> <span class="hljs-string">GiB</span> <span class="hljs-string">avail</span><br>    <span class="hljs-attr">pgs:</span>     <span class="hljs-number">128</span> <span class="hljs-string">active+clean</span><br><br>[<span class="hljs-string">root@ceph_node1</span> <span class="hljs-string">rbd-demo</span>]<span class="hljs-comment"># ^C</span><br><br></code></pre></td></tr></table></figure>

<h2 id="五、RGW对象存储"><a href="#五、RGW对象存储" class="headerlink" title="五、RGW对象存储"></a>五、RGW对象存储</h2><p><strong>5.1 部署RGW存储对象网关</strong></p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs elixir">[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>sudo yum -y install ceph-radosgw.x86_64<br><span class="hljs-comment">#监听7480的端口</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>ceph-deploy rgw create ceph_node1<br><span class="hljs-comment">#可以通过端口去访问</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>curl <span class="hljs-symbol">http:</span>//<span class="hljs-symbol">ceph_node1:</span><span class="hljs-number">7480</span><br>&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;&lt;<span class="hljs-title class_">ListAllMyBucketsResult</span> xmlns=<span class="hljs-string">&quot;http://s3.amazonaws.com/doc/2006-03-01/&quot;</span>&gt;&lt;<span class="hljs-title class_">Owner</span>&gt;&lt;<span class="hljs-title class_">ID</span>&gt;anonymous&lt;/<span class="hljs-title class_">ID</span>&gt;&lt;<span class="hljs-title class_">DisplayName</span>&gt;&lt;/<span class="hljs-title class_">DisplayName</span>&gt;&lt;/<span class="hljs-title class_">Owner</span>&gt;&lt;<span class="hljs-title class_">Buckets</span>&gt;&lt;/<span class="hljs-title class_">Buckets</span>&gt;&lt;/<span class="hljs-title class_">ListAllMyBucketsResult</span>&gt;[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br><span class="hljs-comment">#修改rgw的端口，修改为80端口</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>cat ceph.conf<br>[global]<br>fsid = <span class="hljs-number">04</span>af08e4<span class="hljs-number">-3541</span><span class="hljs-number">-4448</span>-b7b3-f456e1302083<br>mon_initial_members = ceph_node1<br>mon_host = <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span><br>auth_cluster_required = cephx<br>auth_service_required = cephx<br>auth_client_required = cephx<br>public_network = <span class="hljs-number">192.168</span>.<span class="hljs-number">142.0</span>/<span class="hljs-number">24</span><br>cluster_network = <span class="hljs-number">192.168</span>.<span class="hljs-number">241.0</span>/<span class="hljs-number">24</span><br><br>[client.rgw.ceph_node1]<br>rgw_frontends = <span class="hljs-string">&quot;civetweb port=80&quot;</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><span class="hljs-comment">#重启rgw的网关</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo systemctl restart ceph-radosgw.target<br><span class="hljs-comment">#监听80的端口</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo netstat -antupl | grep <span class="hljs-string">&quot;80&quot;</span><br>tcp        <span class="hljs-number">0</span>      <span class="hljs-number">0</span> <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span><span class="hljs-symbol">:</span><span class="hljs-number">80</span>              <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span><span class="hljs-symbol">:*</span>               <span class="hljs-title class_">LISTEN</span>      <span class="hljs-number">116097</span>/radosgw<br><br><br></code></pre></td></tr></table></figure>
<p><strong>5.2 RGW之S3接口使用</strong></p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">#新建一个访问S3的账户<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node1 ~]$ radosgw-<span class="hljs-keyword">admin</span> <span class="hljs-keyword">user</span> <span class="hljs-keyword">create</span> <span class="hljs-comment">--uid ceph-s3-user --display-name &quot;Ceph S3 User Demo&quot;</span><br>#测试S3的接口，需要安装 python-boto 包.<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node1 ~]$ sudo yum -y install python-boto<br>#新建 Python 脚本:<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node1 ~]$ cat s3test.py<br>#!/usr/bin/python<br># -*- coding: utf<span class="hljs-number">-8</span> -*-<br><span class="hljs-keyword">import</span> boto<br><span class="hljs-keyword">import</span> boto.s3.<span class="hljs-keyword">connection</span><br>access_key = <span class="hljs-string">&#x27;DTQTVDPZYJY730YJYLM3&#x27;</span> #modify <span class="hljs-keyword">user</span> key<br>secret_key = <span class="hljs-string">&#x27;w5dHYKreB5aNyrmGXWwwewjVLg8cDA9hMDL7kPsT&#x27;</span><br>conn = boto.connect_s3(<br>        aws_access_key_id = access_key,<br>        aws_secret_access_key = secret_key,<br>        host = <span class="hljs-string">&#x27;192.168.142.134&#x27;</span>,port=<span class="hljs-number">80</span>, #hostname<br>        is_secure=<span class="hljs-keyword">False</span>,calling_format = boto.s3.<span class="hljs-keyword">connection</span>.OrdinaryCallingFormat(),)<br>bucket = conn.create_bucket(<span class="hljs-string">&#x27;ceph-s3-bucket&#x27;</span>) #modify bucket <span class="hljs-type">name</span> <span class="hljs-keyword">is</span> ceph-s3-<span class="hljs-keyword">user</span>-bucket<br><span class="hljs-keyword">for</span> bucket <span class="hljs-keyword">in</span> conn.get_all_buckets():<br>        print &quot;&#123;name&#125;\t&#123;created&#125;&quot;.format(<br>                <span class="hljs-type">name</span> = bucket.name,<br>                created = bucket.creation_date,<br>)<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node1 ~]$<br>#可以看到新建出了一个buckets.<span class="hljs-keyword">index</span>的pool<br>[ceph-<span class="hljs-keyword">admin</span>@ceph_node1 ~]$ ceph osd lspools<br><span class="hljs-number">1</span> ceph-demo<br><span class="hljs-number">2</span> .rgw.root<br><span class="hljs-number">3</span> <span class="hljs-keyword">default</span>.rgw.control<br><span class="hljs-number">4</span> <span class="hljs-keyword">default</span>.rgw.meta<br><span class="hljs-number">5</span> <span class="hljs-keyword">default</span>.rgw.<span class="hljs-keyword">log</span><br><span class="hljs-number">6</span> <span class="hljs-keyword">default</span>.rgw.buckets.<span class="hljs-keyword">index</span><br><br></code></pre></td></tr></table></figure>
<p><strong>5.3 S3cmd管理</strong></p>
<figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs vhdl">#先下载s3cmd的工具<br>[ceph-admin@ceph_node1 ~]$ sudo yum -y install s3cmd<br>#在进行配置<br>[ceph-admin@ceph_node1 ~]$ s3cmd <span class="hljs-comment">--configure</span><br><br>Enter <span class="hljs-keyword">new</span> values <span class="hljs-keyword">or</span> accept defaults <span class="hljs-keyword">in</span> brackets <span class="hljs-keyword">with</span> Enter.<br>Refer <span class="hljs-keyword">to</span> user manual <span class="hljs-keyword">for</span> detailed description <span class="hljs-keyword">of</span> <span class="hljs-keyword">all</span> options.<br><br><span class="hljs-keyword">Access</span> key <span class="hljs-keyword">and</span> Secret key are your identifiers <span class="hljs-keyword">for</span> Amazon S3. Leave them empty <span class="hljs-keyword">for</span> using the env variables.<br><span class="hljs-keyword">Access</span> Key: DTQTVDPZYJY730YJYLM3<br>Secret Key: w5dHYKreB5aNyrmGXWwwewjVLg8cDA9hMDL7kPsT<br><span class="hljs-keyword">Default</span> Region [US]:<br><br><span class="hljs-keyword">Use</span> <span class="hljs-string">&quot;s3.amazonaws.com&quot;</span> <span class="hljs-keyword">for</span> S3 Endpoint <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> modify it <span class="hljs-keyword">to</span> the target Amazon S3.<br>S3 Endpoint [s3.amazonaws.com]: <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span><br><br><span class="hljs-keyword">Use</span> <span class="hljs-string">&quot;%(bucket)s.s3.amazonaws.com&quot;</span> <span class="hljs-keyword">to</span> the target Amazon S3. <span class="hljs-string">&quot;%(bucket)s&quot;</span> <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;%(location)s&quot;</span> vars can be used<br><span class="hljs-keyword">if</span> the target S3 system supports dns based buckets.<br>DNS-style bucket+hostname:<span class="hljs-keyword">port</span> template <span class="hljs-keyword">for</span> accessing a bucket [%(bucket)s.s3.amazonaws.com]: <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span>:<span class="hljs-number">80</span>/%(bucket)s<br><br>Encryption password <span class="hljs-keyword">is</span> used <span class="hljs-keyword">to</span> protect your files from reading<br>by unauthorized persons <span class="hljs-keyword">while</span> <span class="hljs-keyword">in</span> transfer <span class="hljs-keyword">to</span> S3<br>Encryption password:<br>Path <span class="hljs-keyword">to</span> GPG program [/bin/gpg]:<br><br><span class="hljs-keyword">When</span> using secure HTTPS protocol <span class="hljs-keyword">all</span> communication <span class="hljs-keyword">with</span> Amazon S3<br>servers <span class="hljs-keyword">is</span> <span class="hljs-keyword">protected</span> from <span class="hljs-number">3</span>rd party eavesdropping. This method <span class="hljs-keyword">is</span><br>slower than plain HTTP, <span class="hljs-keyword">and</span> can only be proxied <span class="hljs-keyword">with</span> Python <span class="hljs-number">2.7</span> <span class="hljs-keyword">or</span> newer<br><span class="hljs-keyword">Use</span> HTTPS protocol [Yes]: no<br><br><span class="hljs-keyword">On</span> some networks <span class="hljs-keyword">all</span> internet <span class="hljs-keyword">access</span> must go through a HTTP proxy.<br>Try setting it here <span class="hljs-keyword">if</span> you can<span class="hljs-symbol">&#x27;t</span> connect <span class="hljs-keyword">to</span> S3 directly<br>HTTP Proxy server name:<br><br><span class="hljs-keyword">New</span> settings:<br>  <span class="hljs-keyword">Access</span> Key: DTQTVDPZYJY730YJYLM3<br>  Secret Key: w5dHYKreB5aNyrmGXWwwewjVLg8cDA9hMDL7kPsT<br>  <span class="hljs-keyword">Default</span> Region: US<br>  S3 Endpoint: <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span><br>  DNS-style bucket+hostname:<span class="hljs-keyword">port</span> template <span class="hljs-keyword">for</span> accessing a bucket: <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span>:<span class="hljs-number">80</span>/%(bucket)s<br>  Encryption password:<br>  Path <span class="hljs-keyword">to</span> GPG program: /bin/gpg<br>  <span class="hljs-keyword">Use</span> HTTPS protocol: <span class="hljs-literal">False</span><br>  HTTP Proxy server name:<br>  HTTP Proxy server <span class="hljs-keyword">port</span>: <span class="hljs-number">0</span><br><br>Test <span class="hljs-keyword">access</span> <span class="hljs-keyword">with</span> supplied credentials? [Y/n] y<br>Please <span class="hljs-keyword">wait</span>, attempting <span class="hljs-keyword">to</span> list <span class="hljs-keyword">all</span> buckets...<br>Success. Your <span class="hljs-keyword">access</span> key <span class="hljs-keyword">and</span> secret key worked fine :-)<br><br>Now verifying that encryption works...<br><span class="hljs-keyword">Not</span> configured. Never mind.<br><br>Save settings? [y/N] y<br><span class="hljs-keyword">Configuration</span> saved <span class="hljs-keyword">to</span> &#x27;/home/ceph-admin/.s3cfg&#x27;<br>[ceph-admin@ceph_node1 ~]$<br>#可以看到刚刚生成的一个配置文件<br>[ceph-admin@ceph_node1 ~]$ cat /home/ceph-admin/.s3cfg<br>#创建一个对象存储<br>[ceph-admin@ceph_node1 ~]$ s3cmd mb s3://s3cmd-demo<br>Bucket <span class="hljs-symbol">&#x27;s3</span>://s3cmd-demo/&#x27; created<br>#可以看到当下有那些<br>[ceph-admin@ceph_node1 ~]$ s3cmd ls<br><span class="hljs-number">2021</span>-<span class="hljs-number">11</span>-<span class="hljs-number">22</span> <span class="hljs-number">04</span>:<span class="hljs-number">06</span>  s3://ceph-s3-bucket<br><span class="hljs-number">2021</span>-<span class="hljs-number">11</span>-<span class="hljs-number">22</span> <span class="hljs-number">04</span>:<span class="hljs-number">18</span>  s3://s3cmd-demo<br><br>创建、上传、下载、查看、删除<br>#创建<br>s3cmd mb s3://BUCKET<br>#上传<br>[ceph-admin@ceph_node1 ~]$ s3cmd put /etc/fstab s3://s3cmd-demo/test_fstab<br>[ceph-admin@ceph_node1 ~]$ s3cmd put /etc/ s3://s3cmd-demo/etc <span class="hljs-comment">--recursive</span><br>#查看<br>[ceph-admin@ceph_node1 ~]$ s3cmd ls s3://s3cmd-demo/<br>#下载<br>[ceph-admin@ceph_node1 ~]$ s3cmd get s3://s3cmd-demo/etc/resolv.conf resolv.conf<br>#删除<br>[ceph-admin@ceph_node1 ~]$ s3cmd rm s3://s3cmd-demo/test_fstab<br>#查看帮助指导<br>[ceph-admin@ceph_node1 ~]$ s3cmd <span class="hljs-comment">--help </span><br></code></pre></td></tr></table></figure>

<p><strong>5.4 swift风格API接口</strong></p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">RADOS</span>网关用户管理工具常用命令<span class="hljs-selector-tag">-radosgw-admin</span> (<span class="hljs-attribute">http</span>:<span class="hljs-comment">//www.hulihutu.me/?p=236)</span><br><br><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ radosgw-admin user list<br>[<br>    <span class="hljs-string">&quot;ceph-s3-user&quot;</span><br>]<br>#创建一个swift的user，权限是full<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ sudo radosgw-admin subuser create --uid=<span class="hljs-string">&quot;ceph-s3-user&quot;</span> --subuser=<span class="hljs-string">&quot;ceph-s3-user:swift&quot;</span>  --access=full<br>#创建一个secret<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ radosgw-admin key create --subuser=<span class="hljs-string">&quot;ceph-s3-user:swift&quot;</span> --key-type=swift --gen-secret<br><br>#升级pip，低版本直接升级到高版本可能会报错<br>wget <span class="hljs-attribute">https</span>:<span class="hljs-comment">//files.pythonhosted.org/packages/0b/f5/be8e741434a4bf4ce5dbc235aa28ed0666178ea8986ddc10d035023744e6/pip-20.2.4.tar.gz  #下载安装包</span><br>tar -zxvf pip-<span class="hljs-number">20.2</span>.<span class="hljs-number">4</span>.tar.gz  # 解压<br>cd pip-<span class="hljs-number">20.2</span>.<span class="hljs-number">4</span>/<br>sudo python setup.py install #给予权限不然可能安装失败<br>pip install -U pip #再次更新<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ /bin/python -m pip install --upgrade pip<br><br>#安装swift的客户端<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ pip install python-swiftclient<br>#swift查询创建测bucket<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift -A <span class="hljs-attribute">http</span>:<span class="hljs-comment">//192.168.142.134:80/auth -U ceph-s3-user:swift -K Xhitxsypvp5kPE0eWCpxIjatJCU34UznQaeAOAHJ list</span><br>ceph-s3-bucket<br>s3cmd-demo<br><br>#可以定义环境变量<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift list<br>Auth version <span class="hljs-number">1.0</span> requires ST_AUTH, ST_USER, <span class="hljs-keyword">and</span> ST_KEY environment variables<br>to be set or overridden with -A, -U, or -K.<br><br>Auth version <span class="hljs-number">2.0</span> requires OS_AUTH_URL, OS_USERNAME, OS_PASSWORD, <span class="hljs-keyword">and</span><br>OS_TENANT_NAME OS_TENANT_ID to be set or overridden with --os-auth-url,<br>--os-username, --os-password, --os-tenant-name or os-tenant-id. <span class="hljs-attribute">Note</span>:<br>adding <span class="hljs-string">&quot;-V 2&quot;</span> is necessary for this.<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ export ST_AUTH=<span class="hljs-attribute">http</span>:<span class="hljs-comment">//192.168.142.134:80/auth</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ export ST_USER=<span class="hljs-attribute">ceph-s3-user</span>:swift<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ export ST_KEY=Xhitxsypvp5kPE0eWCpxIjatJCU34UznQaeAOAHJ<br>#创建、上传、下载、删除、查看<br>#创建<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift post swift-demo<br>#上传<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift upload swift-demo /etc/passwd<br>#下载<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift download swift-demo etc/passwd<br>#删除<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift delete swift-demo<br>#查看<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]$ swift list<br></code></pre></td></tr></table></figure>

<h2 id="六、CephFS文件存储"><a href="#六、CephFS文件存储" class="headerlink" title="六、CephFS文件存储"></a>六、CephFS文件存储</h2><p><strong>6.1 部署RGW存储对象网关</strong></p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment">#部署mds在ceph-node1节点上</span><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy mds create ceph_node1<br><span class="hljs-comment">#将node2,node3,都部署上mds,配置成高可用模式</span><br>[ceph-admin@ceph_admin cluster]$ ceph-deploy mds create ceph_node2 ceph_node3<br><span class="hljs-comment">#创建谦</span><br>data:<br>    pools:  <span class="hljs-number"> 7 </span>pools,<span class="hljs-number"> 320 </span>pgs<br>    objects:<span class="hljs-number"> 252 </span>objects,<span class="hljs-number"> 42 </span>MiB<br>    usage:   5.2 GiB used,<span class="hljs-number"> 45 </span>GiB /<span class="hljs-number"> 50 </span>GiB avail<br>    pgs:    <span class="hljs-number"> 320 </span>active+clean<br><br><span class="hljs-comment">#创建一个文件系统，设置PG数为8</span><br>[ceph-admin@ceph_node1 ~]$ ceph osd pool create cpehfs_metadata<span class="hljs-number"> 8 </span>8<br>[ceph-admin@ceph_node1 ~]$ ceph osd pool create cephfs_data<span class="hljs-number"> 8 </span>8<br><span class="hljs-comment">#创建后</span><br> data:<br>    pools:  <span class="hljs-number"> 9 </span>pools,<span class="hljs-number"> 336 </span>pgs<br>    objects:<span class="hljs-number"> 252 </span>objects,<span class="hljs-number"> 42 </span>MiB<br>    usage:   5.2 GiB used,<span class="hljs-number"> 45 </span>GiB /<span class="hljs-number"> 50 </span>GiB avail<br>    pgs:     2.381% pgs unknown<br>            <span class="hljs-number"> 328 </span>active+clean<br>            <span class="hljs-number"> 8 </span>  unknown<br><span class="hljs-comment">#查看lspool的资源池             </span><br>[ceph-admin@ceph_node1 ~]$ ceph osd lspools<br>1 ceph-demo<br>2 .rgw.root<br>3 default.rgw.control<br>4 default.rgw.meta<br>5 default.rgw.log<br>6 default.rgw.buckets.index<br>7 default.rgw.buckets.data<br>8 cpehfs_metadata<br>9 cephfs_data<br><br><span class="hljs-comment">#创建文件存储pool后，mds会启用</span><br>[ceph-admin@ceph_node1 ~]$ ceph fs new cephfs-demo cpehfs_metadata cephfs_data<br>new fs with metadata pool<span class="hljs-number"> 8 </span>and data pool 9<br></code></pre></td></tr></table></figure>

<p><img src="/img/Linux/osd2.png" srcset="/img/loading.gif"></p>
<p><strong>6.2 文件系统挂载–内核驱动挂载</strong></p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#例如,path-to-mounted指的是服务器的挂载点   mount-point指的是挂载到哪个地方    name=&#123;user-name&#125; 挂载使用认证的方式</span><br>sudo mount -t ceph :&#123;path-to-mounted&#125; &#123;mount-point&#125; -o name=&#123;user-name&#125;<br>sudo mount -t ceph :<span class="hljs-regexp">/  /m</span>nt/mycephfs -o name=admin<br><br><span class="hljs-comment">#创建一个存放文件</span><br>[ceph-admin@ceph_node1 ~]$ sudo mkdir <span class="hljs-regexp">/mnt/</span>cephfs<br><span class="hljs-comment">#将192.168.142.134的ceph空间挂载到/mnt/cephfs路径上</span><br>[ceph-admin@ceph_node1 ~]$ sudo mount.ceph <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span>:<span class="hljs-number">6789</span>:<span class="hljs-regexp">/  /m</span>nt/cephfs  -o name=admin<br>[ceph-admin@ceph_node1 ~]$ df -h<br>Filesystem               Size  Used Avail Use% Mounted on<br>devtmpfs                 <span class="hljs-number">898</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">898</span>M   <span class="hljs-number">0</span>% /dev<br>tmpfs                    <span class="hljs-number">910</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">910</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/dev/</span>shm<br>tmpfs                    <span class="hljs-number">910</span>M   <span class="hljs-number">45</span>M  <span class="hljs-number">866</span>M   <span class="hljs-number">5</span>% /run<br>tmpfs                    <span class="hljs-number">910</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">910</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/sys/</span>fs/cgroup<br><span class="hljs-regexp">/dev/m</span>apper<span class="hljs-regexp">/centos-root   17G  2.9G   15G  17% /</span><br><span class="hljs-regexp">/dev/</span>sda1               <span class="hljs-number">1014</span>M  <span class="hljs-number">176</span>M  <span class="hljs-number">839</span>M  <span class="hljs-number">18</span>% /boot<br>tmpfs                    <span class="hljs-number">182</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">182</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/run/u</span>ser/<span class="hljs-number">0</span><br><span class="hljs-regexp">/dev/</span>rbd0                <span class="hljs-number">2.0</span>G  <span class="hljs-number">3.0</span>M  <span class="hljs-number">1.9</span>G   <span class="hljs-number">1</span>% <span class="hljs-regexp">/mnt/</span>rbd-demo<br><span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span>:<span class="hljs-number">6789</span>:<span class="hljs-regexp">/    15G     0   15G   0% /m</span>nt/cephfs<br><br></code></pre></td></tr></table></figure>

<p><strong>6.3 文件系统挂载–用户空间挂载</strong></p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs awk">[ceph-admin@ceph_node1 ~]$ ceph-fuse -h<br>usage: ceph-fuse [-n client.username] [-m mon-ip-addr:mon-port] &lt;mount point&gt; [OPTIONS]<br>  --client_mountpoint/-r &lt;sub_directory&gt;<br>                    use sub_directory as the mounted root, rather than the full Ceph tree.<br>                    <br>                    <br><span class="hljs-comment">#安装ceph-fuse客户端</span><br>[ceph-admin@ceph_node1 ~]$ sudo yum -y install ceph-fuse<br>[ceph-admin@ceph_node1 ~]$ mkdir <span class="hljs-regexp">/mnt/</span>ceph-fuse<br><br><span class="hljs-comment">#挂载-m指的是mon的节点，可以挂载多个mon的节点, -n是ceph内置的admin</span><br>[ceph-admin@ceph_node1 ~]$ sudo ceph-fuse -n client.admin -m <span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span>:<span class="hljs-number">6789</span> <span class="hljs-regexp">/mnt/</span>ceph-fuse<br>ceph-fuse[<span class="hljs-number">2021</span>-<span class="hljs-number">11</span>-<span class="hljs-number">23</span> <span class="hljs-number">21</span>:<span class="hljs-number">44</span>:<span class="hljs-number">17.656</span> <span class="hljs-number">7</span>f72b94b1f80 -<span class="hljs-number">1</span> init, newargv = <span class="hljs-number">0</span>x5596d9d2f930 newargc=<span class="hljs-number">9</span><br><span class="hljs-number">132714</span>]: starting ceph client<br>ceph-fuse[<span class="hljs-number">132714</span>]: starting fuse<br>[ceph-admin@ceph_node1 ~]$ df -h<br>Filesystem               Size  Used Avail Use% Mounted on<br>devtmpfs                 <span class="hljs-number">898</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">898</span>M   <span class="hljs-number">0</span>% /dev<br>tmpfs                    <span class="hljs-number">910</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">910</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/dev/</span>shm<br>tmpfs                    <span class="hljs-number">910</span>M   <span class="hljs-number">45</span>M  <span class="hljs-number">866</span>M   <span class="hljs-number">5</span>% /run<br>tmpfs                    <span class="hljs-number">910</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">910</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/sys/</span>fs/cgroup<br><span class="hljs-regexp">/dev/m</span>apper<span class="hljs-regexp">/centos-root   17G  2.9G   15G  18% /</span><br><span class="hljs-regexp">/dev/</span>sda1               <span class="hljs-number">1014</span>M  <span class="hljs-number">176</span>M  <span class="hljs-number">839</span>M  <span class="hljs-number">18</span>% /boot<br>tmpfs                    <span class="hljs-number">182</span>M     <span class="hljs-number">0</span>  <span class="hljs-number">182</span>M   <span class="hljs-number">0</span>% <span class="hljs-regexp">/run/u</span>ser/<span class="hljs-number">0</span><br><span class="hljs-regexp">/dev/</span>rbd0                <span class="hljs-number">2.0</span>G  <span class="hljs-number">3.0</span>M  <span class="hljs-number">1.9</span>G   <span class="hljs-number">1</span>% <span class="hljs-regexp">/mnt/</span>rbd-demo<br><span class="hljs-number">192.168</span>.<span class="hljs-number">142.134</span>:<span class="hljs-number">6789</span>:<span class="hljs-regexp">/    15G     0   15G   0% /m</span>nt/cephfs<br>ceph-fuse                 <span class="hljs-number">15</span>G     <span class="hljs-number">0</span>   <span class="hljs-number">15</span>G   <span class="hljs-number">0</span>% <span class="hljs-regexp">/mnt/</span>ceph-fuse<br><br></code></pre></td></tr></table></figure>

<p><strong>6.4 删除之前创建失败的osd</strong></p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-comment">#从集群中删除down掉的osd</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd rm osd.<span class="hljs-number">1</span><br>removed osd.<span class="hljs-number">1</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>ceph osd tree<br><span class="hljs-title class_">ID</span> <span class="hljs-title class_">CLASS</span> <span class="hljs-title class_">WEIGHT</span>  <span class="hljs-title class_">TYPE</span> <span class="hljs-title class_">NAME</span>                <span class="hljs-title class_">STATUS</span> <span class="hljs-title class_">REWEIGHT</span> <span class="hljs-title class_">PRI</span>-<span class="hljs-title class_">AFF</span><br><span class="hljs-number">-1</span>       <span class="hljs-number">0.87900</span> root default<br><span class="hljs-number">-3</span>       <span class="hljs-number">0.29300</span>     host szbd-ceph-node1<br> <span class="hljs-number">0</span>   hdd <span class="hljs-number">0.29300</span>         osd.<span class="hljs-number">0</span>                up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br><span class="hljs-number">-5</span>       <span class="hljs-number">0.29300</span>     host szbd-ceph-node2<br> <span class="hljs-number">5</span>   hdd <span class="hljs-number">0.29300</span>         osd.<span class="hljs-number">5</span>                up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br><span class="hljs-number">-7</span>       <span class="hljs-number">0.29300</span>     host szbd-ceph-node3<br> <span class="hljs-number">6</span>   hdd <span class="hljs-number">0.29300</span>         osd.<span class="hljs-number">6</span>                up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br> <span class="hljs-number">2</span>             <span class="hljs-number">0</span> osd.<span class="hljs-number">2</span>                      down        <span class="hljs-number">0</span> <span class="hljs-number">1.00000</span><br> <span class="hljs-number">3</span>             <span class="hljs-number">0</span> osd.<span class="hljs-number">3</span>                      down        <span class="hljs-number">0</span> <span class="hljs-number">1.00000</span><br> <span class="hljs-number">4</span>             <span class="hljs-number">0</span> osd.<span class="hljs-number">4</span>                      down        <span class="hljs-number">0</span> <span class="hljs-number">1.00000</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd rm osd.<span class="hljs-number">2</span><br>removed osd.<span class="hljs-number">2</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd rm osd.<span class="hljs-number">3</span><br>removed osd.<span class="hljs-number">3</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd rm osd.<span class="hljs-number">4</span><br>removed osd.<span class="hljs-number">4</span><br><span class="hljs-comment">#从crush中删除</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd crush rm osd.<span class="hljs-number">1</span><br>device <span class="hljs-string">&#x27;osd.1&#x27;</span> does <span class="hljs-keyword">not</span> appear <span class="hljs-keyword">in</span> the crush map<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd crush rm osd.<span class="hljs-number">2</span><br>device <span class="hljs-string">&#x27;osd.2&#x27;</span> does <span class="hljs-keyword">not</span> appear <span class="hljs-keyword">in</span> the crush map<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd crush rm osd.<span class="hljs-number">3</span><br>device <span class="hljs-string">&#x27;osd.3&#x27;</span> does <span class="hljs-keyword">not</span> appear <span class="hljs-keyword">in</span> the crush map<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph osd crush rm osd.<span class="hljs-number">4</span><br>device <span class="hljs-string">&#x27;osd.4&#x27;</span> does <span class="hljs-keyword">not</span> appear <span class="hljs-keyword">in</span> the crush map<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br><br><span class="hljs-comment">#从中删除掉认证的信息</span><br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph auth del osd.<span class="hljs-number">1</span><br>updated<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph auth del osd.<span class="hljs-number">2</span><br>updated<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph auth del osd.<span class="hljs-number">3</span><br>updated<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>sudo ceph auth del osd.<span class="hljs-number">4</span><br>updated<br>[ceph-admin<span class="hljs-variable">@szbd</span>-ceph-node1 ~]<span class="hljs-variable">$ </span>ceph  auth list<br><br></code></pre></td></tr></table></figure>

<p><strong>6.5 REBALANCING数据重平衡</strong></p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment">#临时关闭rebalance</span><br><span class="hljs-comment">#当在做rebalance的时候，每个osd都会按照osd_max_backfills指定数量的线程来同步,如果该数值比较大，同步会比较快，但是#会影响部分性能；另外数据同步时，是走的cluster_network,而客户端连接是用的public_network,生产环境建议这两个网络用</span><br><span class="hljs-comment">#万兆网络，较少网络传输的影响；</span><br><span class="hljs-comment">#设置标志位</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd set norebalance<br><span class="hljs-comment">#关闭数据填充</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd set nobackfill<br><span class="hljs-comment">#取消标志位</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd unset nobackfill<br>nobackfill is unset<br><span class="hljs-comment">#开启数据填充</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd unset norebalance<br>norebalance is unset<br><br><span class="hljs-comment">#可以看硬盘哪个有延迟，有延迟的就可能是硬盘有坏道</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ceph]<span class="hljs-variable">$ </span>ceph osd perf<br></code></pre></td></tr></table></figure>
<p><img src="/img/Linux/balance.png" srcset="/img/loading.gif"></p>
<h2 id="七、Ceph集群运维"><a href="#七、Ceph集群运维" class="headerlink" title="七、Ceph集群运维"></a>七、Ceph集群运维</h2><p><strong>7.1 Ceph守护服务管理</strong></p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs less">#开启全部进程<br><span class="hljs-selector-tag">sudo</span> <span class="hljs-selector-tag">systemctl</span> <span class="hljs-selector-tag">start</span> <span class="hljs-selector-tag">ceph</span><span class="hljs-selector-class">.target</span><br>#检查全部<span class="hljs-selector-tag">ceph</span>的进程<br><span class="hljs-selector-tag">sudo</span> <span class="hljs-selector-tag">systemctl</span> <span class="hljs-selector-tag">status</span> <span class="hljs-selector-tag">ceph</span>\*<span class="hljs-selector-class">.service</span> <span class="hljs-selector-tag">ceph</span>\*<span class="hljs-selector-class">.target</span>  <br><br>#启动<span class="hljs-selector-tag">ceph</span>节点上所有特定类型的守护进程(start、stop、restart）<br>sudo systemctl start ceph-osd.target<br>sudo systemctl start ceph-mon.target<br>sudo systemctl start ceph-mds.target<br><br>#启动ceph上某一个特定的守护进程(start、stop、restart）<br>sudo systemctl start ceph-osd<span class="hljs-variable">@&#123;id&#125;</span><br>sudo systemctl start ceph-mon<span class="hljs-variable">@&#123;hostname&#125;</span><br>sudo systemctl start ceph-mds<span class="hljs-variable">@&#123;hostname&#125;</span><br><br># check status of osd.<span class="hljs-number">12</span><br>sudo systemctl status ceph-osd<span class="hljs-variable">@12</span>      <br><br>#会关闭掉在执行机器上osd的关闭<br>sudo systemctl stop ceph-osd.target<br><br>#开启其中的某一个osd<br>sudo systemctl start ceph-osd<span class="hljs-variable">@4</span>   #建议在生产环境中使用这种，影响最小。<br></code></pre></td></tr></table></figure>
<p><strong>7.2 Ceph服务日志分析</strong></p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gradle">#日志文件路径 <span class="hljs-regexp">/var/</span>log<span class="hljs-regexp">/ceph/</span><br>tail ceph-osd.<span class="hljs-number">0</span>.log<br><br></code></pre></td></tr></table></figure>

<p><strong>7.3 集群状态</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs bash">osd<br><span class="hljs-comment">#检测集群的状态</span><br>ceph -s<br><span class="hljs-comment">#动态可以看到集群的状态</span><br>ceph -w<br><span class="hljs-comment">#可以看到集群资源池空间分配的情况</span><br>ceph <span class="hljs-built_in">df</span><br><span class="hljs-comment">#可以看到很完整的osd的信息</span><br>ceph osd dump<br><span class="hljs-comment">#可以整个集群资源池的状态</span><br>ceph osd tree<br><span class="hljs-comment">#每个osd的大小</span><br>ceph osd <span class="hljs-built_in">df</span><br><br><br>mon<br><span class="hljs-comment">#监视mon的状态</span><br>ceph mon <span class="hljs-built_in">stat</span><br><span class="hljs-comment">#完整的mon信息</span><br>ceph mon dump<br><br><br>mds<br>ceph mds <span class="hljs-built_in">stat</span><br>ceph fs dump<br><br><br><span class="hljs-comment">#用admin socket可以查询到守护进程的配置状态信息</span><br>[root@ceph_node1 ceph]<span class="hljs-comment"># ceph --admin-daemon /var/run/ceph/ceph-mon.ceph_node1.asok config show</span><br><span class="hljs-comment">#更多的查询</span><br>ceph --admin-daemon /var/run/ceph/ceph-mgr.ceph_node1.asok <span class="hljs-built_in">help</span><br></code></pre></td></tr></table></figure>

<p><strong>7.4 Pool资源池的管理</strong></p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">#设置pool资源池的自动收缩放模式<br>ceph osd pool <span class="hljs-keyword">set</span> &lt;pool-<span class="hljs-type">name</span>&gt; pg_autoscale_mode &lt;mode&gt;<br>例子:<br>ceph osd pool <span class="hljs-keyword">set</span> cephfs_data pg_autoscale_mode <span class="hljs-keyword">on</span><br><br>#可以设置pg最小的值<br>ceph osd pool <span class="hljs-keyword">set</span> &lt;pool-<span class="hljs-type">name</span>&gt; pg_num_min &lt;num&gt;<br>#创建一个新的pool池，pg_num的值是可选的。如果不指定pg_num，集群可以(默认情况下)根据池中存储的数据量自动为您调优<br>ceph osd pool <span class="hljs-keyword">create</span> &#123;pool-<span class="hljs-type">name</span>&#125; [pg_num] [pgp_num]<br>ceph osd pool <span class="hljs-keyword">set</span> &#123;pool-<span class="hljs-type">name</span>&#125; pg_autoscale_mode (<span class="hljs-keyword">on</span>|<span class="hljs-keyword">off</span>|warn)<br><br>https://docs.ceph.com/en/latest/rados/operations/placement-<span class="hljs-keyword">groups</span>/(官网pool的文档)<br><br></code></pre></td></tr></table></figure>

<p><strong>7.5 Ceph参数调整配置</strong></p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-comment">###重启服务后不生效</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd pool create pool-demo <span class="hljs-number">12</span> <span class="hljs-number">12</span><br>pool <span class="hljs-string">&#x27;pool-demo&#x27;</span> created<br><span class="hljs-comment">#删除一个pool</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># ceph osd pool rm pool-demo pool-demo --yes-i-really-really-mean-it</span><br><span class="hljs-title class_">Error</span> <span class="hljs-symbol">EPERM:</span> pool deletion is disabled; you must first set the mon_allow_pool_delete config option to <span class="hljs-literal">true</span> before you can destroy a pool<br><span class="hljs-comment">#查看配置</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># ceph --admin-daemon /var/run/ceph/ceph-mon.ceph_node1.asok config show | grep mon_allow_pool_delete</span><br>    <span class="hljs-string">&quot;mon_allow_pool_delete&quot;</span>: <span class="hljs-string">&quot;false&quot;</span>,<br><span class="hljs-comment">#可以这样去调设置，调整了其中一个mon节点，其余节点也必须要调整，因为他是一个集群</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># ceph --admin-daemon /var/run/ceph/ceph-mon.ceph_node1.asok config set mon_allow_pool_delete true</span><br>&#123;<br>    <span class="hljs-string">&quot;success&quot;</span>: <span class="hljs-string">&quot;mon_allow_pool_delete = &#x27;true&#x27; &quot;</span><br>&#125;<br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment">#</span><br><span class="hljs-comment">#删除pool成功</span><br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># ceph osd pool rm  pool-demo pool-demo --yes-i-really-really-mean-it</span><br>pool <span class="hljs-string">&#x27;pool-demo&#x27;</span> removed<br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment">#</span><br><br><br><span class="hljs-comment">###长期生效</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>cat ceph.conf | grep mon_allow_pool_delete<br>mon_allow_pool_delete = <span class="hljs-literal">true</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><span class="hljs-comment">#要写进ceph.conf里头，并推到mon的节点上，才会永久生效。</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>cat ceph.conf | grep mon_allow_pool_delete<br>mon_allow_pool_delete = <span class="hljs-literal">true</span><br><span class="hljs-comment">#推到mon节点</span><br>[ceph-admin<span class="hljs-variable">@ceph_admin</span> cluster]<span class="hljs-variable">$ </span>ceph-deploy --overwrite-conf config push ceph_node1<br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment"># ceph --admin-daemon /var/run/ceph/ceph-mon.ceph_node1.asok config show | grep mon_allow_pool_delete</span><br>    <span class="hljs-string">&quot;mon_allow_pool_delete&quot;</span>: <span class="hljs-string">&quot;true&quot;</span>,<br>[root<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-comment">#</span><br><br></code></pre></td></tr></table></figure>

<h2 id="八、定义Crush-map规则"><a href="#八、定义Crush-map规则" class="headerlink" title="八、定义Crush map规则"></a>八、定义Crush map规则</h2><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs crystal">crush算法通过进行分配将不同的数据落到不同的osd中，定义crush规则一般都是以host位单位<br><span class="hljs-comment">#查看crush</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd crush tree<br><span class="hljs-comment">#可以查看到完整的crush规则</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>ceph osd crush dump<br><br></code></pre></td></tr></table></figure>
<p><strong>8.1 定义Crush规则</strong></p>
<p><img src="/img/Linux/crush_info.png" srcset="/img/loading.gif"></p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><code class="hljs crystal">这里我有四个机器,将按照上面的图来定制我的crushmap的规则<br><span class="hljs-comment">#将crushmap下的二进制bin文件下载下来</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd getcrushmap -o crushmap.bin<br><span class="hljs-comment">#将crushmap.bin文件更改为txt文件</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>crushtool -d crushmap.bin -o crushmap.txt<br><br><br><span class="hljs-comment">##将进行重新更改，更改为以下。</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>cat crushmap.txt<br><span class="hljs-comment"># begin crush map</span><br>tunable choose_local_tries <span class="hljs-number">0</span><br>tunable choose_local_fallback_tries <span class="hljs-number">0</span><br>tunable choose_total_tries <span class="hljs-number">50</span><br>tunable chooseleaf_descend_once <span class="hljs-number">1</span><br>tunable chooseleaf_vary_r <span class="hljs-number">1</span><br>tunable chooseleaf_stable <span class="hljs-number">1</span><br>tunable straw_calc_version <span class="hljs-number">1</span><br>tunable allowed_bucket_algs <span class="hljs-number">54</span><br><br><span class="hljs-comment"># devices</span><br>device <span class="hljs-number">0</span> osd.<span class="hljs-number">0</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span></span><br>device <span class="hljs-number">1</span> osd.<span class="hljs-number">1</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span></span><br>device <span class="hljs-number">2</span> osd.<span class="hljs-number">2</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span></span><br>device <span class="hljs-number">3</span> osd.<span class="hljs-number">3</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span></span><br><span class="hljs-comment">#device 4 osd.4 class hdd</span><br>device <span class="hljs-number">4</span> osd.<span class="hljs-number">4</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ssd</span></span><br><br><br><span class="hljs-comment"># types</span><br><span class="hljs-keyword">type</span> <span class="hljs-number">0</span> osd<br><span class="hljs-keyword">type</span> <span class="hljs-number">1</span> host<br><span class="hljs-keyword">type</span> <span class="hljs-number">2</span> chassis<br><span class="hljs-keyword">type</span> <span class="hljs-number">3</span> rack<br><span class="hljs-keyword">type</span> <span class="hljs-number">4</span> row<br><span class="hljs-keyword">type</span> <span class="hljs-number">5</span> pdu<br><span class="hljs-keyword">type</span> <span class="hljs-number">6</span> pod<br><span class="hljs-keyword">type</span> <span class="hljs-number">7</span> room<br><span class="hljs-keyword">type</span> <span class="hljs-number">8</span> datacenter<br><span class="hljs-keyword">type</span> <span class="hljs-number">9</span> zone<br><span class="hljs-keyword">type</span> <span class="hljs-number">10</span> region<br><span class="hljs-keyword">type</span> <span class="hljs-number">11</span> root<br><br><span class="hljs-comment"># buckets</span><br>host ceph_node1 &#123;<br>        id -<span class="hljs-number">3</span>           <span class="hljs-comment"># do not change unnecessarily</span><br>        id -<span class="hljs-number">4</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span>         <span class="hljs-comment"># do not change unnecessarily</span></span><br>        <span class="hljs-comment"># weight 0.010</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item osd.<span class="hljs-number">0</span> weight <span class="hljs-number">0.010</span><br>&#125;<br>host ceph_node2 &#123;<br>        id -<span class="hljs-number">5</span>           <span class="hljs-comment"># do not change unnecessarily</span><br>        id -<span class="hljs-number">6</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span>         <span class="hljs-comment"># do not change unnecessarily</span></span><br>        <span class="hljs-comment"># weight 0.010</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item osd.<span class="hljs-number">1</span> weight <span class="hljs-number">0.010</span><br>&#125;<br>host ceph_node3 &#123;<br>        id -<span class="hljs-number">7</span>           <span class="hljs-comment"># do not change unnecessarily</span><br>        id -<span class="hljs-number">8</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span>         <span class="hljs-comment"># do not change unnecessarily</span></span><br>        <span class="hljs-comment"># weight 0.010</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item osd.<span class="hljs-number">2</span> weight <span class="hljs-number">0.010</span><br>&#125;<br>host ceph_node4 &#123;<br>        id -<span class="hljs-number">9</span>           <span class="hljs-comment"># do not change unnecessarily</span><br>        id -<span class="hljs-number">10</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span>                <span class="hljs-comment"># do not change unnecessarily</span></span><br>        <span class="hljs-comment"># weight 0.020</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item osd.<span class="hljs-number">3</span> weight <span class="hljs-number">0.010</span><br>&#125;<br><br>host ceph_node4_ssd &#123;<br>        <span class="hljs-comment"># weight 0.020</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item osd.<span class="hljs-number">4</span> weight <span class="hljs-number">0.010</span><br>&#125;<br>root default &#123;<br>        id -<span class="hljs-number">1</span>           <span class="hljs-comment"># do not change unnecessarily</span><br>        id -<span class="hljs-number">2</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">hdd</span>         <span class="hljs-comment"># do not change unnecessarily</span></span><br>        <span class="hljs-comment"># weight 0.049</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item ceph_node1 weight <span class="hljs-number">0.010</span><br>        item ceph_node2 weight <span class="hljs-number">0.010</span><br>        item ceph_node3 weight <span class="hljs-number">0.010</span><br>        item ceph_node4 weight <span class="hljs-number">0.010</span><br>&#125;<br>root data &#123;<br>        <span class="hljs-comment"># weight 0.049</span><br>        alg straw2<br>        hash <span class="hljs-number">0</span>  <span class="hljs-comment"># rjenkins1</span><br>        item ceph_node4_ssd weight <span class="hljs-number">0.010</span><br>&#125;<br><br><br><span class="hljs-comment"># rules</span><br>rule replicated_rule &#123;<br>        id <span class="hljs-number">0</span><br>        <span class="hljs-keyword">type</span> replicated<br>        min_size <span class="hljs-number">1</span><br>        max_size <span class="hljs-number">10</span><br>        step take default<br>        step chooseleaf firstn <span class="hljs-number">0</span> <span class="hljs-keyword">type</span> host<br>        step emit<br>&#125;<br><br>rule demo_rule &#123;<br>        id <span class="hljs-number">11</span><br>        <span class="hljs-keyword">type</span> replicated<br>        min_size <span class="hljs-number">1</span><br>        max_size <span class="hljs-number">10</span><br>        step take data<br>        step chooseleaf firstn <span class="hljs-number">0</span> <span class="hljs-keyword">type</span> host<br>        step emit<br>&#125;<br><br><span class="hljs-comment"># end crush map</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br><span class="hljs-comment">#进行重新编译成二进制文件</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>crushtool -c crushmap.txt -o crushmap-new.bin<br><span class="hljs-comment">##更改前</span><br>[ceph-admin<span class="hljs-variable">@ceph_node2</span> ~]<span class="hljs-variable">$ </span>sudo ceph osd tree<br>ID CLASS WEIGHT  TYPE NAME           STATUS REWEIGHT PRI-AFF<br>-<span class="hljs-number">1</span>       <span class="hljs-number">0.04898</span> root default<br>-<span class="hljs-number">3</span>       <span class="hljs-number">0.00980</span>     host ceph_node1<br> <span class="hljs-number">0</span>   hdd <span class="hljs-number">0.00980</span>         osd.<span class="hljs-number">0</span>           up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br>-<span class="hljs-number">5</span>       <span class="hljs-number">0.00980</span>     host ceph_node2<br> <span class="hljs-number">1</span>   hdd <span class="hljs-number">0.00980</span>         osd.<span class="hljs-number">1</span>           up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br>-<span class="hljs-number">7</span>       <span class="hljs-number">0.00980</span>     host ceph_node3<br> <span class="hljs-number">2</span>   hdd <span class="hljs-number">0.00980</span>         osd.<span class="hljs-number">2</span>           up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br>-<span class="hljs-number">9</span>       <span class="hljs-number">0.01959</span>     host ceph_node4<br> <span class="hljs-number">3</span>   hdd <span class="hljs-number">0.00980</span>         osd.<span class="hljs-number">3</span>           up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br> <span class="hljs-number">4</span>   hdd <span class="hljs-number">0.00980</span>         osd.<span class="hljs-number">4</span>           up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br>[ceph-admin<span class="hljs-variable">@ceph_node2</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><span class="hljs-comment">#将新的二进制文件应用到osd中</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd  setcrushmap -i crushmap-new.bin<br><span class="hljs-comment">###更改后</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd tree<br>ID  CLASS WEIGHT  TYPE NAME               STATUS REWEIGHT PRI-AFF<br>-<span class="hljs-number">12</span>       <span class="hljs-number">0.00999</span> root data<br>-<span class="hljs-number">11</span>       <span class="hljs-number">0.00999</span>     host ceph_node4_ssd<br>  <span class="hljs-number">4</span>   ssd <span class="hljs-number">0.00999</span>         osd.<span class="hljs-number">4</span>               up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br> -<span class="hljs-number">1</span>       <span class="hljs-number">0.03998</span> root default<br> -<span class="hljs-number">3</span>       <span class="hljs-number">0.00999</span>     host ceph_node1<br>  <span class="hljs-number">0</span>   hdd <span class="hljs-number">0.00999</span>         osd.<span class="hljs-number">0</span>               up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br> -<span class="hljs-number">5</span>       <span class="hljs-number">0.00999</span>     host ceph_node2<br>  <span class="hljs-number">1</span>   hdd <span class="hljs-number">0.00999</span>         osd.<span class="hljs-number">1</span>               up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br> -<span class="hljs-number">7</span>       <span class="hljs-number">0.00999</span>     host ceph_node3<br>  <span class="hljs-number">2</span>   hdd <span class="hljs-number">0.00999</span>         osd.<span class="hljs-number">2</span>               up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br> -<span class="hljs-number">9</span>       <span class="hljs-number">0.00999</span>     host ceph_node4<br>  <span class="hljs-number">3</span>   hdd <span class="hljs-number">0.00999</span>         osd.<span class="hljs-number">3</span>               up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br><span class="hljs-comment">###测试，将cephfs_data更改为新的demo_rule规则</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd pool ls<br>ceph-demo<br>.rgw.root<br>default.rgw.control<br>default.rgw.meta<br>default.rgw.log<br>default.rgw.buckets.index<br>default.rgw.buckets.data<br>cpehfs_metadata<br>cephfs_data<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd pool get cephfs_data crush_rule<br><span class="hljs-symbol">crush_rule:</span> replicated_rule<br><span class="hljs-comment">#可以看到，现在多了一个我们定义的demo_rule规则</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd crush rule ls<br>replicated_rule<br>demo_rule<br><span class="hljs-comment">####可以看到已经修改成功</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd pool set cephfs_data crush_rule demo_rule<br>set pool <span class="hljs-number">9</span> crush_rule to demo_rule<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd pool get cephfs_data crush_rule<br><span class="hljs-symbol">crush_rule:</span> demo_rule<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br><br><span class="hljs-comment">###重新将其修改回原本的crushmap规则</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd pool set cephfs_data crush_rule replicated_rule<br>set pool <span class="hljs-number">9</span> crush_rule to replicated_rule<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$ </span>ceph osd setcrushmap -i crushmap.bin<br><span class="hljs-number">13</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> crushmap]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br><br><span class="hljs-comment">###注意事项三点:</span><br><span class="hljs-number">1</span>. 再添加硬盘的时候，就初始化crushmap规则<br><span class="hljs-number">2</span>. 要备份bin文件，出问题后迅速还原<br><span class="hljs-number">3</span>. 需要再ceph.conf 添加一条 osd crush update on start = <span class="hljs-literal">false</span> , 否则重启后，osd会还原(再管理节点进行)<br><span class="hljs-number">4</span>. 将修改后ceph.conf推送到其他node节点上 ceph-deploy config push ceph_node1 ceph_node2 ceph_node3<br><br></code></pre></td></tr></table></figure>

<h2 id="九、RBD高级功能"><a href="#九、RBD高级功能" class="headerlink" title="九、RBD高级功能"></a>九、RBD高级功能</h2><p><strong>9.1 RBD回收站机制</strong></p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs stylus">#在ceph-demo得pool下创建ceph-trash<span class="hljs-selector-class">.img</span> <span class="hljs-number">10</span>M<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd create ceph-demo/ceph-trash<span class="hljs-selector-class">.img</span> <span class="hljs-attr">--size</span> <span class="hljs-number">10</span>M<br>#查看详细信息<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd info ceph-demo/ceph-trash<span class="hljs-selector-class">.img</span><br>rbd image <span class="hljs-string">&#x27;ceph-trash.img&#x27;</span>:<br>        size <span class="hljs-number">10</span> MiB <span class="hljs-keyword">in</span> <span class="hljs-number">3</span> objects<br>        <span class="hljs-attribute">order</span> <span class="hljs-number">22</span> (<span class="hljs-number">4</span> MiB objects)<br>        snapshot_count: <span class="hljs-number">0</span><br>        id: d3bbc0b41b79<br>        block_name_prefix: rbd_data<span class="hljs-selector-class">.d3bbc0b41b79</span><br>        format: <span class="hljs-number">2</span><br>        features: layering, exclusive-lock, object-map, fast-diff, deep-flatten<br>        op_features:<br>        flags:<br>        create_timestamp: Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">03</span>:<span class="hljs-number">52</span>:<span class="hljs-number">02</span> <span class="hljs-number">2021</span><br>        access_timestamp: Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">03</span>:<span class="hljs-number">52</span>:<span class="hljs-number">02</span> <span class="hljs-number">2021</span><br>        modify_timestamp: Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">03</span>:<span class="hljs-number">52</span>:<span class="hljs-number">02</span> <span class="hljs-number">2021</span><br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$<br>###删除该镜像后，回收站是没有得，所以不建议这么操作，可以将他移动到回收站并设置过期时间，需要的时候还可以恢复。<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd rm ceph-demo/ceph-trash<span class="hljs-selector-class">.img</span><br>#查看pool池下有哪些<span class="hljs-selector-tag">img</span><br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd -<span class="hljs-selector-tag">p</span> ceph-demo ls<br>#移动到回收站<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd trash move ceph-demo/ceph-trash<span class="hljs-selector-class">.img</span> <span class="hljs-attr">--expires-at</span> <span class="hljs-number">20211201</span><br>#回收站可以看到<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd -<span class="hljs-selector-tag">p</span> ceph-demo trash ls<br>d3cc5b52e46f ceph-trash<span class="hljs-selector-class">.img</span><br>#从回收站恢复到原来的位置<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd trash restore  -<span class="hljs-selector-tag">p</span> ceph-demo  d3cc5b52e46f<br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$ rbd -<span class="hljs-selector-tag">p</span> ceph-demo ls<br>ceph-trash<span class="hljs-selector-class">.img</span><br>rbd-demo<span class="hljs-selector-class">.img</span><br><span class="hljs-selector-attr">[ceph-admin@ceph_node1 ~]</span>$<br></code></pre></td></tr></table></figure>

<p><strong>9.2 RBD快照制作及快照数据恢复</strong></p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-comment">#制作一个块</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd create ceph-demo/rbd-snapshoot.img --image-feature layering --size 20M<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd info ceph-demo/rbd-snapshoot.img<br>rbd image <span class="hljs-string">&#x27;rbd-snapshoot.img&#x27;</span>:<br>        size <span class="hljs-number">20</span> MiB <span class="hljs-keyword">in</span> <span class="hljs-number">5</span> objects<br>        order <span class="hljs-number">22</span> (<span class="hljs-number">4</span> MiB objects)<br>        <span class="hljs-symbol">snapshot_count:</span> <span class="hljs-number">0</span><br>        <span class="hljs-symbol">id:</span> d3f2eb1db27a<br>        <span class="hljs-symbol">block_name_prefix:</span> rbd_data.d3f2eb1db27a<br>        <span class="hljs-symbol">format:</span> <span class="hljs-number">2</span><br>        <span class="hljs-symbol">features:</span> layering<br>        <span class="hljs-symbol">op_features:</span><br>        <span class="hljs-symbol">flags:</span><br>        <span class="hljs-symbol">create_timestamp:</span> Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">04</span><span class="hljs-symbol">:</span><span class="hljs-number">34</span><span class="hljs-symbol">:</span><span class="hljs-number">57</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">access_timestamp:</span> Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">04</span><span class="hljs-symbol">:</span><span class="hljs-number">34</span><span class="hljs-symbol">:</span><span class="hljs-number">57</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">modify_timestamp:</span> Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">04</span><span class="hljs-symbol">:</span><span class="hljs-number">34</span><span class="hljs-symbol">:</span><span class="hljs-number">57</span> <span class="hljs-number">2021</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><span class="hljs-comment">#将这个块map起来</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo rbd device map ceph-demo/rbd-snapshoot.img<br>/dev/rbd1<br><span class="hljs-comment">#格式化做成一个文件系统</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo mkfs.ext4 /dev/rbd1<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo mkdir /mnt/rbd_snapshoot<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo mount /dev/rbd1 /mnt/rbd_snapshoot/<br><br><span class="hljs-comment">##拍摄快照成功, 格式为rbd snap create pool_name/img_name<span class="hljs-doctag">@time</span>.name</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap create ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@snap_20211130</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap ls ceph-demo/rbd-snapshoot.img<br><span class="hljs-variable constant_">SNAPID</span> <span class="hljs-variable constant_">NAME</span>          <span class="hljs-variable constant_">SIZE</span>   <span class="hljs-variable constant_">PROTECTED</span> <span class="hljs-variable constant_">TIMESTAMP</span><br>     <span class="hljs-number">4</span> snap_20211130 <span class="hljs-number">20</span> MiB           Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">04</span><span class="hljs-symbol">:</span><span class="hljs-number">56</span><span class="hljs-symbol">:</span><span class="hljs-number">16</span> <span class="hljs-number">2021</span><br><br><br><span class="hljs-comment">##测试数据损坏了，进行快照恢复。</span><br><span class="hljs-comment">#1.查看要恢复快照的快照名称</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap ls ceph-demo/rbd-snapshoot.img<br><span class="hljs-variable constant_">SNAPID</span> <span class="hljs-variable constant_">NAME</span>          <span class="hljs-variable constant_">SIZE</span>   <span class="hljs-variable constant_">PROTECTED</span> <span class="hljs-variable constant_">TIMESTAMP</span><br>     <span class="hljs-number">4</span> snap_20211130 <span class="hljs-number">20</span> MiB           Tue Nov <span class="hljs-number">30</span> <span class="hljs-number">04</span><span class="hljs-symbol">:</span><span class="hljs-number">56</span><span class="hljs-symbol">:</span><span class="hljs-number">16</span> <span class="hljs-number">2021</span><br><span class="hljs-comment">#2. 开始回滚</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap rollback ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@snap_20211130</span><br>Rolling back to <span class="hljs-symbol">snapshot:</span> <span class="hljs-number">100</span>% complete...done.<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> rbd_snapshoot]<span class="hljs-variable">$ </span>ls<br>lost+found<br><span class="hljs-comment">#3.重新挂载才可以看到数据恢复成功</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo umount /mnt/rbd_snapshoot/<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo mount /dev/rbd1 /mnt/rbd_snapshoot/<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> rbd_snapshoot]<span class="hljs-variable">$ </span>ls<br>lost+found  test<br><span class="hljs-comment">#4.删除不用的快照</span><br>rbd snap rm &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap rm  ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@snap_20211130</span><br>Removing <span class="hljs-symbol">snap:</span> <span class="hljs-number">100</span>% complete...done.<br><br></code></pre></td></tr></table></figure>

<p><strong>9.3 RBD镜像克隆</strong></p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment">#制作rbd-snapshoot的快照</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap create ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span><br><span class="hljs-comment">#保护template快照后，无法进行删除</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap protect ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap rm ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span><br>Removing <span class="hljs-symbol">snap:</span> <span class="hljs-number">0</span>% complete...failed.<span class="hljs-number">2021</span>-<span class="hljs-number">11</span>-<span class="hljs-number">30</span> <span class="hljs-number">23</span>:<span class="hljs-number">0</span>7:<span class="hljs-number">21.960</span> <span class="hljs-number">7</span>fd516efdc80 -<span class="hljs-number">1</span> <span class="hljs-symbol">librbd:</span>:<span class="hljs-symbol">Operations:</span> snapshot is <span class="hljs-keyword">protected</span><br><span class="hljs-symbol">rbd:</span> snapshot <span class="hljs-string">&#x27;template&#x27;</span> is <span class="hljs-keyword">protected</span> from removal.<br><br><span class="hljs-comment">#将快照克隆格式为: rbd clone &#123;pool-name&#125;/&#123;image-name&#125;@&#123;snap-name&#125;  path_name/clone_name.img</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd clone ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span> ceph-demo/vm1-clone.img<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd clone ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span> ceph-demo/vm2-clone.img<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd -p ceph-demo ls<br>ceph-trash.img<br>rbd-demo.img<br>rbd-snapshoot.img<br>vm1-clone.img<br>vm2-clone.img<br><br><span class="hljs-comment">#将克隆的镜像map上去，并挂载查看镜像里的文件是否一致</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo rbd device map ceph-demo/vm1-clone.img<br><span class="hljs-regexp">/dev/rbd</span>2<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo mkdir /mnt/vm1<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo mount /dev/rbd2 /mnt/vm1<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo ls /mnt/vm1<br>lost+found  test<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><br></code></pre></td></tr></table></figure>
<p><img src="/img/Linux/rbd1.png" srcset="/img/loading.gif"><br><img src="/img/Linux/rbd2.png" srcset="/img/loading.gif"><br><strong>9.3 RBD解除依赖关系</strong></p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-comment">##rbd解除父子依赖关系，解除关系后，删除镜像就没有问题了，flags: 空</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd children ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span><br>ceph-demo/vm1-clone.img<br>ceph-demo/vm2-clone.img<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd flatten ceph-demo/vm1-clone.img<br><span class="hljs-title class_">Image</span> <span class="hljs-symbol">flatten:</span> <span class="hljs-number">100</span>% complete...done.<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd info ceph-demo/vm1-clone.img<br>rbd image <span class="hljs-string">&#x27;vm1-clone.img&#x27;</span>:<br>        size <span class="hljs-number">20</span> <span class="hljs-title class_">MiB</span> <span class="hljs-keyword">in</span> <span class="hljs-number">5</span> objects<br>        order <span class="hljs-number">22</span> (<span class="hljs-number">4</span> <span class="hljs-title class_">MiB</span> objects)<br>        <span class="hljs-symbol">snapshot_count:</span> <span class="hljs-number">0</span><br>        <span class="hljs-symbol">id:</span> d43f4e8edeb0<br>        <span class="hljs-symbol">block_name_prefix:</span> rbd_data.d43f4e8edeb0<br>        <span class="hljs-symbol">format:</span> <span class="hljs-number">2</span><br>        <span class="hljs-symbol">features:</span> layering<br>        <span class="hljs-symbol">op_features:</span><br>        <span class="hljs-symbol">flags:</span><br>        <span class="hljs-symbol">create_timestamp:</span> <span class="hljs-title class_">Tue</span> <span class="hljs-title class_">Nov</span> <span class="hljs-number">30</span> <span class="hljs-number">23</span><span class="hljs-symbol">:</span><span class="hljs-number">15</span><span class="hljs-symbol">:</span><span class="hljs-number">57</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">access_timestamp:</span> <span class="hljs-title class_">Tue</span> <span class="hljs-title class_">Nov</span> <span class="hljs-number">30</span> <span class="hljs-number">23</span><span class="hljs-symbol">:</span><span class="hljs-number">15</span><span class="hljs-symbol">:</span><span class="hljs-number">57</span> <span class="hljs-number">2021</span><br>        <span class="hljs-symbol">modify_timestamp:</span> <span class="hljs-title class_">Tue</span> <span class="hljs-title class_">Nov</span> <span class="hljs-number">30</span> <span class="hljs-number">23</span><span class="hljs-symbol">:</span><span class="hljs-number">15</span><span class="hljs-symbol">:</span><span class="hljs-number">57</span> <span class="hljs-number">2021</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$</span><br><span class="hljs-variable"></span><span class="hljs-comment">#去除掉protect的保护</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap unprotect ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap rm ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@template</span><br><span class="hljs-title class_">Removing</span> <span class="hljs-symbol">snap:</span> <span class="hljs-number">100</span>% complete...done.<br></code></pre></td></tr></table></figure>
<p><strong>9.4 RBD备份与恢复</strong></p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-comment">#创建一个rbd-snapshoot.img的快照名叫snap-demo，</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap create ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@snap</span>-demo<br><span class="hljs-comment">#查看镜像的快照</span><br>rbd snap ls &#123;pool-name&#125;/&#123;image-name&#125;<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd snap ls ceph-demo/rbd-snapshoot.img<br><span class="hljs-variable constant_">SNAPID</span> <span class="hljs-variable constant_">NAME</span>      <span class="hljs-variable constant_">SIZE</span>   <span class="hljs-variable constant_">PROTECTED</span> <span class="hljs-variable constant_">TIMESTAMP</span><br>    <span class="hljs-number">10</span> snap-demo <span class="hljs-number">20</span> MiB           Wed Dec  <span class="hljs-number">1</span> <span class="hljs-number">01</span><span class="hljs-symbol">:</span><span class="hljs-number">58</span><span class="hljs-symbol">:</span><span class="hljs-number">34</span> <span class="hljs-number">2021</span><br><br><span class="hljs-comment">#将创建镜像的快照导出</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo rbd export ceph-demo/rbd-snapshoot.img<span class="hljs-variable">@snap</span>-demo /root/export_img/rbd-snapshoot.img<br>Exporting <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>sudo ls /root/export_img/<br>rbd-snapshoot.img<br><br><span class="hljs-comment">#将原来的数据删除掉，然后卸载硬盘，重新用新的快照恢复。</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> rbd_snapshoot]<span class="hljs-variable">$ </span>sudo rm -f test<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> rbd_snapshoot]<span class="hljs-variable">$ </span>sudo umount /mnt/rbd_snapshoot<br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd import rbd-snapshoot.img ceph-demo/rbd-snapshoot-new.img</span><br>Importing <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd device map ceph-demo/rbd-snapshoot-new.img</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># mount /dev/rbd3 /mnt/rbd_snapshoot/</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># ls   /mnt/rbd_snapshoot/</span><br>lost+found  test<br><br><br><br><span class="hljs-comment">#在实际项目中使用就是，定期做快照，然后导出某个时间点快照的数据，然后导出增量的快照的数据。</span><br>例如：<br>备份：<br>对所有的rbd的image做一个基础快照，然后导出这个快照的数据，然后设置每天定时做快照，导出快照时间点之间的数据，这样每天导出来的就是一个增量的数据了。<br>设置循环周期，比如三天为一个周期。每三天循环一次，自动删除三天前的备份。<br>恢复：<br>从第一个快照导入，然后按照顺序导入增量的快照即可。<br><br><br><span class="hljs-comment">#定期增量备份</span><br><span class="hljs-comment">#0.创建一个pool</span><br>ceph osd pool create ceph-demo <span class="hljs-number">32</span> <span class="hljs-number">32</span><br><br><span class="hljs-comment">#1.#制作一个镜像块设备</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> ~]<span class="hljs-variable">$ </span>rbd create ceph-demo/rbd-snapshoot.img --image-feature layering --size 20M<br><br><span class="hljs-comment">#2. 将镜像做块设备的挂载</span><br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-variable">$ </span>sudo rbd device map ceph-demo/rbd-snapshoot.img<br>/dev/rbd0<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-variable">$ </span>sudo mkfs.ext4 /dev/rbd0<br>[ceph-admin<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-variable">$ </span>sudo mount /dev/rbd0 /mnt/rbd_snapshoot/<br><br><span class="hljs-comment">#3.第一次写入数据</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># sudo echo &quot;第一次写入数据&quot; &gt;&gt; /mnt/rbd_snapshoot/v1_write.txt</span><br><br><span class="hljs-comment">#4.第一次拍摄实例快照</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd snap create ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v1</span><br><br><span class="hljs-comment">#5.第一次将拍摄的快照全量备份</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd export-diff ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v1 rbd_snapshoot_v1_backup</span><br>Exporting <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br><br><span class="hljs-comment">#6.继续写入数据</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># echo &quot;第二次写入数据&quot; &gt;&gt; /mnt/rbd_snapshoot/v2_write.txt</span><br><br><span class="hljs-comment">#7.第二次拍摄实例快照</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd snap create ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v2</span><br><br><span class="hljs-comment">#8.第二次将拍摄的快照进行备份</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd export-diff ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v2 rbd_snapshoot_v2_backup</span><br>Exporting <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br><br><span class="hljs-comment">#9.第三次写入数据</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># echo &quot;第三次写入数据&quot; &gt;&gt; /mnt/rbd_snapshoot/v3_write.txt</span><br><br><span class="hljs-comment">#10.第三次拍摄实例快照</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd snap create ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v3</span><br><br><span class="hljs-comment">#11.第三次将拍摄的快照进行备份</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd export-diff ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v3 rbd_snapshoot_v3_backup</span><br>Exporting <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br><br><span class="hljs-comment">#12.查看当前共有3个快照，分别将快照的差异数据，取出来。</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd snap ls ceph-demo/rbd-snapshoot.img</span><br><span class="hljs-variable constant_">SNAPID</span> <span class="hljs-variable constant_">NAME</span>             <span class="hljs-variable constant_">SIZE</span>   <span class="hljs-variable constant_">PROTECTED</span> <span class="hljs-variable constant_">TIMESTAMP</span><br>     <span class="hljs-number">6</span> rbd_snapshoot_v1 <span class="hljs-number">20</span> MiB           Thu Dec  <span class="hljs-number">2</span> <span class="hljs-number">07</span><span class="hljs-symbol">:</span><span class="hljs-number">07</span><span class="hljs-symbol">:</span><span class="hljs-number">36</span> <span class="hljs-number">2021</span><br>     <span class="hljs-number">7</span> rbd_snapshoot_v2 <span class="hljs-number">20</span> MiB           Thu Dec  <span class="hljs-number">2</span> <span class="hljs-number">07</span><span class="hljs-symbol">:</span><span class="hljs-number">11</span><span class="hljs-symbol">:</span><span class="hljs-number">27</span> <span class="hljs-number">2021</span><br>     <span class="hljs-number">8</span> rbd_snapshoot_v3 <span class="hljs-number">20</span> MiB           Thu Dec  <span class="hljs-number">2</span> <span class="hljs-number">07</span><span class="hljs-symbol">:</span><span class="hljs-number">14</span><span class="hljs-symbol">:</span><span class="hljs-number">54</span> <span class="hljs-number">2021</span><br><br><span class="hljs-comment">#13.将v2的快照和v1的快照的差异数据取出来</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd export-diff --from-snap rbd_snapshoot_v1 ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v2   rbd_snapshoot_v2_v1</span><br>Exporting <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br><br><br><span class="hljs-comment">#13.将v3的快照和v2的快照的差异数据取出来</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd export-diff --from-snap rbd_snapshoot_v2 ceph-demo/rbd-snapshoot.img<span class="hljs-doctag">@rbd</span>_snapshoot_v3  rbd_snapshoot_v3_v2</span><br>Exporting <span class="hljs-symbol">image:</span> <span class="hljs-number">100</span>% complete...done.<br><br><br><span class="hljs-comment">#数据备份恢复</span><br><span class="hljs-comment">#1.新建一个块设备镜像并格式化且挂载到文件夹下</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd create ceph-demo/rbd_backup.img --image-feature layering --size 30M</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd device map ceph-demo/rbd_backup_2.img</span><br>/dev/rbd2<br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># mkfs.ext4 /dev/rbd2</span><br>[root<span class="hljs-variable">@ceph_node1</span> mnt]<span class="hljs-comment"># mount /dev/rbd2 /mnt/rbd_backup/</span><br><br><span class="hljs-comment">#2.导入恢复数据需要依次导入，比如：第一次备份的文件先导入，再导入第一次第二次的差异数据文件，再导入第二次全量备份的文件，接着再导入第二次和第三次差异的数据，最后再导入第三次最后一次备份的数据文件。</span><br><span class="hljs-comment">#2.1 导入第一次全量备份的数据</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd import-diff rbd_snapshoot_v1_backup ceph-demo/rbd_backup.img</span><br>Importing image <span class="hljs-symbol">diff:</span> <span class="hljs-number">100</span>% complete...done.<br><span class="hljs-comment">#2.2 导入第二次和第一次的备份的差异数据</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd import-diff rbd_snapshoot_v2_v1 ceph-demo/rbd_backup.img</span><br>Importing image <span class="hljs-symbol">diff:</span> <span class="hljs-number">100</span>% complete...done.<br><span class="hljs-comment">#2.3 导入第二次和第三全量备份的数据</span><br>[root<span class="hljs-variable">@ceph_node1</span> export_img]<span class="hljs-comment"># rbd import-diff rbd_snapshoot_v3_v2 ceph-demo/rbd_backup.img</span><br>Importing image <span class="hljs-symbol">diff:</span> <span class="hljs-number">100</span>% complete...done.<br><br></code></pre></td></tr></table></figure>

<p>未完待续….</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Linux/">Linux</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/">分布式存储</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/08/31/MDT/windows_autoinstall_01/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Windows自动化装机部署（一）WDS环境准备</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/31/Linux/kickstart/">
                        <span class="hidden-mobile">Pxe+Dhcp+Httpd+Tftp+Kickstart搭建无人值守服务器</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      $('#local-search-input').on('click', function() {
        searchFunc(path, 'local-search-input', 'local-search-result');
      });
      $('#modalSearch').on('shown.bs.modal', function() {
        $('#local-search-input').focus();
      });
    })()
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>



</body>
</html>
